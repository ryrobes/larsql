cascade_id: artifact_workflow_demo
description: 'Demonstrates the complete artifact workflow:

  1. Iterate on visualizations with request_decision (HTMX blocking)

  2. Publish final polished version with create_artifact (persistent)


  Shows how artifacts become permanent gallery items while request_decision

  is ephemeral iteration tool.

  '
inputs_schema:
  dataset_name: What dataset to analyze
memory: artifact_test
cells:
- name: draft_and_iterate
  skills:
  - request_decision
  - create_artifact
  - route_to
  - run_code
  - linux_shell
  - sql_search
  - request_decision
  - sql_query
  handoffs:
  - finalize
  takes:
    factor: 3
    models:
    - openai/gpt-5.2
  rules:
    max_turns: 10
  instructions: "Analyze / find dataset: {{ input.dataset_name }}\n\n## Workflow (Each\
    \ Take Explores Different Visualizations):\n\n1. **Get Data (you have many\
    \ tools at your command)\n\n2. **Create a professional and data-dense Dashboard**\n\
    \n3. **Request approval** using request_decision with HTMX:\n   - Show your unique\
    \ visualization\n   - Ask: \"Does this visualization effectively show the data?\"\
    \n   - Buttons: \"Approve\" or \"Request Changes\"\n\n4. **If approved:** Use\
    \ create_artifact to publish, and then route_to the finalize step.\n"
- name: finalize
  skills:
  - create_artifact
  instructions: 'Artifact created: {{ outputs.draft_and_iterate.artifact_id }}

    (Please create it, if not done already)


    Provide a summary of:

    - What the artifact contains

    - Key insights from the data

    - How to access it (Artifacts gallery)

    '
  context:
    from:
    - draft_and_iterate
