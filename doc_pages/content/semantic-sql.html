<h1>Semantic SQL</h1>
<p class="lead">
  Extend SQL with natural language understanding, LLM-powered functions, and semantic operators.
  RVBBIT transforms your queries through intelligent rewriting - no database modifications needed.
</p>

<div class="callout callout-info">
  <div class="callout-title"><iconify-icon icon="mdi:lightbulb-outline"></iconify-icon> Design Philosophy</div>
  <p>
    <strong>Cascades All The Way Down.</strong> Every semantic operator in RVBBIT is backed by a cascade
    definition. This means operators are declarative YAML files, not compiled code. You can inspect,
    modify, or create new operators without touching Python - just add a cascade file and restart.
  </p>
</div>

<div class="toc">
  <div class="toc-title">On This Page</div>
  <ul>
    <li><a href="#architecture">Architecture Overview</a></li>
    <li><a href="#query-pipeline">Query Processing Pipeline</a></li>
    <li><a href="#operators">Semantic Operators</a></li>
    <li><a href="#udf-system">UDF System</a></li>
    <li><a href="#sql-server">PostgreSQL Wire Protocol Server</a></li>
    <li><a href="#annotations">Annotation System</a></li>
    <li><a href="#caching">Caching Strategies</a></li>
    <li><a href="#custom-operators">Creating Custom Operators</a></li>
    <li><a href="#map-run">RVBBIT MAP/RUN Statements</a></li>
    <li><a href="#best-practices">Best Practices</a></li>
  </ul>
</div>

<h2 id="architecture">Architecture Overview</h2>

<p>
  RVBBIT's semantic SQL doesn't modify your database engine. Instead, it uses <strong>query rewriting</strong>
  to transform semantic operators into standard SQL + UDF calls that execute on DuckDB (in-process) or
  ClickHouse (persistence layer).
</p>

<div class="feature-grid">
  <div class="feature-card">
    <div class="feature-card-icon"><iconify-icon icon="mdi:file-document-edit"></iconify-icon></div>
    <h4>Query Rewriting</h4>
    <p>
      Your SQL with semantic operators is parsed, transformed, and rewritten into standard SQL
      with UDF calls. The original query never reaches the database directly.
    </p>
  </div>
  <div class="feature-card">
    <div class="feature-card-icon magenta"><iconify-icon icon="mdi:function"></iconify-icon></div>
    <h4>Cascade-Backed UDFs</h4>
    <p>
      Each semantic function is implemented as a cascade. When a UDF executes, it runs the
      corresponding cascade with full observability, caching, and cost tracking.
    </p>
  </div>
  <div class="feature-card">
    <div class="feature-card-icon" style="color: var(--green);"><iconify-icon icon="mdi:auto-fix"></iconify-icon></div>
    <h4>Dynamic Discovery</h4>
    <p>
      Operators are discovered at startup from <code>cascades/semantic_sql/</code>. Add a new cascade file,
      restart, and your operator is available - no code changes needed.
    </p>
  </div>
</div>

<h3>System Components</h3>

<table>
  <thead>
    <tr>
      <th>Component</th>
      <th>Role</th>
      <th>Location</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><strong>SQL Rewriter</strong></td>
      <td>Transforms semantic SQL to standard SQL + UDFs</td>
      <td><code>sql_rewriter.py</code>, <code>semantic_operators.py</code></td>
    </tr>
    <tr>
      <td><strong>Operator Registry</strong></td>
      <td>Discovers and indexes cascade-backed operators</td>
      <td><code>registry.py</code>, <code>dynamic_operators.py</code></td>
    </tr>
    <tr>
      <td><strong>UDF Registration</strong></td>
      <td>Registers Python functions as DuckDB UDFs</td>
      <td><code>udf.py</code></td>
    </tr>
    <tr>
      <td><strong>PostgreSQL Server</strong></td>
      <td>Wire protocol server for SQL client connectivity</td>
      <td><code>postgres_server.py</code></td>
    </tr>
    <tr>
      <td><strong>Cascade Executor</strong></td>
      <td>Runs the actual LLM workflows for each UDF call</td>
      <td><code>executor.py</code>, <code>runner.py</code></td>
    </tr>
  </tbody>
</table>

<h2 id="query-pipeline">Query Processing Pipeline</h2>

<p>
  When you send a query with semantic operators, it flows through a multi-stage transformation
  pipeline before execution. Understanding this pipeline helps you write efficient queries and
  debug issues.
</p>

<div class="mermaid-container">
<pre class="mermaid">
stateDiagram-v2
    direction TB

    [*] --> Receive: SQL Query

    state "Stage 1: Syntax Detection" as Stage1 {
        direction LR
        S1_Check --> S1_MAP: RVBBIT MAP?
        S1_Check --> S1_RUN: RVBBIT RUN?
        S1_Check --> S1_EMBED: RVBBIT EMBED?
        S1_Check --> S1_Normal: Standard Query
        S1_MAP --> S1_Transform: Batch cascade
        S1_RUN --> S1_Transform: Single cascade
        S1_EMBED --> S1_Transform: Vector indexing
        S1_Normal --> S1_Next
        S1_Transform --> S1_Next
    }

    state "Stage 2: Annotation Parsing" as Stage2 {
        direction LR
        S2_Scan --> S2_Model: model hints
        S2_Scan --> S2_Threshold: thresholds
        S2_Scan --> S2_Candidates: candidates config
        S2_Model --> S2_Inject
        S2_Threshold --> S2_Inject
        S2_Candidates --> S2_Inject
        S2_Inject --> S2_Done: Modified criteria
    }

    state "Stage 3: Operator Rewriting" as Stage3 {
        direction LR
        S3_Tokenize --> S3_Match: Safe tokenization
        S3_Match --> S3_Infix: Infix operators
        S3_Match --> S3_Function: Function calls
        S3_Match --> S3_Aggregate: Aggregates
        S3_Infix --> S3_Rewrite: col MEANS 'x'
        S3_Function --> S3_Rewrite: SUMMARIZE()
        S3_Aggregate --> S3_Rewrite: GROUP BY TOPICS()
        S3_Rewrite --> S3_Done: UDF calls
    }

    state "Stage 4: Execution" as Stage4 {
        direction LR
        S4_DuckDB --> S4_UDF: UDF invoked
        S4_UDF --> S4_Cache: Check cache
        S4_Cache --> S4_Hit: Cache hit
        S4_Cache --> S4_Miss: Cache miss
        S4_Miss --> S4_Cascade: Run cascade
        S4_Cascade --> S4_Store: Store result
        S4_Hit --> S4_Return
        S4_Store --> S4_Return
    }

    Receive --> Stage1
    Stage1 --> Stage2
    Stage2 --> Stage3
    Stage3 --> Stage4
    Stage4 --> [*]: Results
</pre>
</div>

<div class="callout callout-tip">
  <div class="callout-title"><iconify-icon icon="mdi:information-outline"></iconify-icon> Pipeline Stages</div>
  <p><strong>Stage 1 (Syntax Detection):</strong> Identifies RVBBIT-specific statements (MAP, RUN, EMBED) and handles them specially.</p>
  <p><strong>Stage 2 (Annotation Parsing):</strong> Extracts <code>-- @</code> annotations and injects hints into criteria strings.</p>
  <p><strong>Stage 3 (Operator Rewriting):</strong> Token-aware transformation of semantic operators to UDF calls. Avoids matching inside strings/comments.</p>
  <p><strong>Stage 4 (Execution):</strong> DuckDB executes the rewritten query, invoking cascade-backed UDFs with multi-level caching.</p>
</div>

<h3>Rewriting Examples</h3>

<p>Here's how different query patterns are transformed:</p>

<div class="code-block">
  <div class="code-block-header">
    <span class="code-block-lang">Infix Operator Rewriting</span>
  </div>
  <div class="code-block-content">
    <pre><span class="cmt">-- Original</span>
<span class="kw">SELECT</span> * <span class="kw">FROM</span> tickets
<span class="kw">WHERE</span> description <span class="fn">MEANS</span> <span class="str">'urgent customer issue'</span>;

<span class="cmt">-- Rewritten to</span>
<span class="kw">SELECT</span> * <span class="kw">FROM</span> tickets
<span class="kw">WHERE</span> <span class="fn">semantic_matches</span>(<span class="str">'urgent customer issue'</span>, description);</pre>
  </div>
</div>

<div class="code-block">
  <div class="code-block-header">
    <span class="code-block-lang">Score-Based Filtering</span>
  </div>
  <div class="code-block-content">
    <pre><span class="cmt">-- Original</span>
<span class="kw">SELECT</span> * <span class="kw">FROM</span> articles
<span class="kw">WHERE</span> content <span class="fn">ABOUT</span> <span class="str">'machine learning'</span> > <span class="num">0.7</span>;

<span class="cmt">-- Rewritten to</span>
<span class="kw">SELECT</span> * <span class="kw">FROM</span> articles
<span class="kw">WHERE</span> <span class="fn">semantic_score</span>(<span class="str">'machine learning'</span>, content) > <span class="num">0.7</span>;</pre>
  </div>
</div>

<div class="code-block">
  <div class="code-block-header">
    <span class="code-block-lang">Aggregate Function Rewriting</span>
  </div>
  <div class="code-block-content">
    <pre><span class="cmt">-- Original</span>
<span class="kw">SELECT</span> category, <span class="fn">SUMMARIZE</span>(review_text)
<span class="kw">FROM</span> reviews
<span class="kw">GROUP BY</span> category;

<span class="cmt">-- Rewritten to</span>
<span class="kw">SELECT</span> category, <span class="fn">summarize_2</span>(<span class="fn">to_json</span>(<span class="fn">LIST</span>(review_text)))
<span class="kw">FROM</span> reviews
<span class="kw">GROUP BY</span> category;</pre>
  </div>
</div>

<div class="code-block">
  <div class="code-block-header">
    <span class="code-block-lang">Dimension Function (Semantic GROUP BY)</span>
  </div>
  <div class="code-block-content">
    <pre><span class="cmt">-- Original</span>
<span class="kw">SELECT</span> <span class="fn">TOPICS</span>(title, <span class="num">5</span>) <span class="kw">AS</span> topic, <span class="kw">COUNT</span>(*) <span class="kw">AS</span> cnt
<span class="kw">FROM</span> articles
<span class="kw">GROUP BY</span> topic;

<span class="cmt">-- Rewritten to (simplified)</span>
<span class="kw">WITH</span> _topics_json <span class="kw">AS</span> (
  <span class="kw">SELECT</span> <span class="fn">llm_topics_discover</span>(<span class="fn">to_json</span>(<span class="fn">LIST</span>(<span class="kw">DISTINCT</span> title)), <span class="num">5</span>) <span class="kw">AS</span> topics
  <span class="kw">FROM</span> articles
),
_classified <span class="kw">AS</span> (
  <span class="kw">SELECT</span> *, <span class="fn">llm_classify_single</span>(title, _topics_json.topics) <span class="kw">AS</span> _topic
  <span class="kw">FROM</span> articles, _topics_json
)
<span class="kw">SELECT</span> _topic <span class="kw">AS</span> topic, <span class="kw">COUNT</span>(*) <span class="kw">AS</span> cnt
<span class="kw">FROM</span> _classified
<span class="kw">GROUP BY</span> _topic;</pre>
  </div>
</div>

<h3>Token-Aware Safety</h3>

<p>
  The rewriter tokenizes SQL before pattern matching, preventing false positives inside strings,
  comments, and quoted identifiers:
</p>

<div class="code-block">
  <div class="code-block-header">
    <span class="code-block-lang">Safe Rewriting</span>
  </div>
  <div class="code-block-content">
    <pre><span class="cmt">-- This MEANS inside a string is NOT rewritten</span>
<span class="kw">SELECT</span> <span class="str">'What this MEANS is important'</span> <span class="kw">AS</span> note;
<span class="cmt">-- Output: 'What this MEANS is important' (unchanged)</span>

<span class="cmt">-- This MEANS in SQL is rewritten</span>
<span class="kw">SELECT</span> * <span class="kw">FROM</span> docs <span class="kw">WHERE</span> title <span class="fn">MEANS</span> <span class="str">'report'</span>;
<span class="cmt">-- Output: ... WHERE semantic_matches('report', title)</span></pre>
  </div>
</div>

<h2 id="operators">Semantic Operators</h2>

<p>
  RVBBIT ships with 50+ built-in operators organized into categories. Each is backed by a cascade
  in <code>cascades/semantic_sql/</code>.
</p>

<h3>Operator Categories</h3>

<table>
  <thead>
    <tr>
      <th>Category</th>
      <th>Examples</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><strong>Filtering</strong></td>
      <td><code>MEANS</code>, <code>ABOUT</code>, <code>~</code>, <code>SIMILAR_TO</code></td>
      <td>Boolean/score filters based on semantic meaning</td>
    </tr>
    <tr>
      <td><strong>Logic</strong></td>
      <td><code>CONTRADICTS</code>, <code>IMPLIES</code>, <code>ALIGNS</code></td>
      <td>Semantic logic checking between texts</td>
    </tr>
    <tr>
      <td><strong>Transformation</strong></td>
      <td><code>ASK</code>, <code>EXTRACTS</code>, <code>CONDENSE</code>, <code>NORMALIZE</code></td>
      <td>Per-row text transformation and extraction</td>
    </tr>
    <tr>
      <td><strong>Aggregation</strong></td>
      <td><code>SUMMARIZE</code>, <code>THEMES</code>, <code>CONSENSUS</code>, <code>DEDUPE</code></td>
      <td>LLM-powered aggregates (work with GROUP BY)</td>
    </tr>
    <tr>
      <td><strong>Dimension</strong></td>
      <td><code>TOPICS()</code>, <code>SENTIMENT()</code>, <code>NARRATIVE()</code></td>
      <td>Semantic GROUP BY - batch classification</td>
    </tr>
    <tr>
      <td><strong>Parsing</strong></td>
      <td><code>PARSE</code>, <code>PARSE_NAME</code>, <code>PARSE_ADDRESS</code>, <code>SMART_JSON</code></td>
      <td>Structure extraction with structural caching</td>
    </tr>
    <tr>
      <td><strong>Data Quality</strong></td>
      <td><code>QUALITY</code>, <code>VALID</code>, <code>ANONYMIZE</code></td>
      <td>Data assessment and cleaning</td>
    </tr>
    <tr>
      <td><strong>MDM</strong></td>
      <td><code>MATCH_PAIR</code>, <code>GOLDEN_RECORD</code>, <code>COALESCE_SMART</code></td>
      <td>Master data management primitives</td>
    </tr>
    <tr>
      <td><strong>Vector</strong></td>
      <td><code>EMBED</code>, <code>VECTOR_SEARCH</code>, <code>HYBRID_SEARCH</code></td>
      <td>Embedding generation and similarity search</td>
    </tr>
  </tbody>
</table>

<p>
  For detailed documentation of each operator, see <a href="#operators" data-link>Built-in Operators</a>.
</p>

<h3>Operator Shapes</h3>

<p>Operators come in three shapes, determining how they integrate with SQL:</p>

<div class="feature-grid">
  <div class="feature-card">
    <div class="feature-card-icon"><iconify-icon icon="mdi:table-row"></iconify-icon></div>
    <h4>SCALAR</h4>
    <p>Processes one row at a time. Called once per row in the result set.</p>
    <p class="stat">Examples: <code>MEANS</code>, <code>SCORE</code>, <code>ASK</code>, <code>PARSE</code></p>
  </div>
  <div class="feature-card">
    <div class="feature-card-icon magenta"><iconify-icon icon="mdi:sigma"></iconify-icon></div>
    <h4>AGGREGATE</h4>
    <p>Processes multiple rows, returns one result per group. Works with GROUP BY.</p>
    <p class="stat">Examples: <code>SUMMARIZE</code>, <code>THEMES</code>, <code>CONSENSUS</code></p>
  </div>
  <div class="feature-card">
    <div class="feature-card-icon" style="color: var(--green);"><iconify-icon icon="mdi:shape"></iconify-icon></div>
    <h4>DIMENSION</h4>
    <p>Two-pass: discovers buckets from all values, then classifies each row.</p>
    <p class="stat">Examples: <code>TOPICS()</code>, <code>SENTIMENT()</code>, <code>NARRATIVE()</code></p>
  </div>
</div>

<h2 id="udf-system">UDF System</h2>

<p>
  At execution time, rewritten queries call User-Defined Functions (UDFs) registered with DuckDB.
  These UDFs are the bridge between SQL and cascade execution.
</p>

<h3>Core UDFs</h3>

<table>
  <thead>
    <tr>
      <th>UDF</th>
      <th>Purpose</th>
      <th>Example</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code>rvbbit_udf(instructions, value)</code></td>
      <td>Simple LLM transformation per row</td>
      <td><code>SELECT rvbbit_udf('Extract brand', name) FROM products</code></td>
    </tr>
    <tr>
      <td><code>rvbbit_cascade_udf(path, inputs)</code></td>
      <td>Full cascade execution per row</td>
      <td><code>SELECT rvbbit_cascade_udf('traits/analyze.yaml', json_object('text', desc))</code></td>
    </tr>
    <tr>
      <td><code>rvbbit_run_batch(path, rows, table)</code></td>
      <td>Batch cascade with temp table</td>
      <td>Used by <code>RVBBIT RUN</code> statements</td>
    </tr>
    <tr>
      <td><code>rvbbit_map_parallel(path, rows, workers)</code></td>
      <td>Parallel cascade execution</td>
      <td>Used by <code>RVBBIT MAP</code> with <code>PARALLEL</code></td>
    </tr>
  </tbody>
</table>

<h3>Embedding UDFs</h3>

<table>
  <thead>
    <tr>
      <th>UDF</th>
      <th>Purpose</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code>semantic_embed(text, model?)</code></td>
      <td>Generate embedding vector for text</td>
    </tr>
    <tr>
      <td><code>vector_search_json_N(query, table, limit?, threshold?)</code></td>
      <td>Vector similarity search, returns JSON file path</td>
    </tr>
    <tr>
      <td><code>similar_to(text1, text2)</code></td>
      <td>Cosine similarity between two texts</td>
    </tr>
    <tr>
      <td><code>trait(name, args_json)</code></td>
      <td>Call any registered trait as a function</td>
    </tr>
  </tbody>
</table>

<h3>LLM Aggregate UDFs</h3>

<p>
  Aggregate UDFs collect values and process them in a single LLM call. DuckDB doesn't support
  function overloading, so aggregates use numbered suffixes:
</p>

<div class="code-block">
  <div class="code-block-header">
    <span class="code-block-lang">Aggregate UDF Naming</span>
  </div>
  <div class="code-block-content">
    <pre><span class="cmt">-- These are the actual UDFs registered with DuckDB:</span>
summarize_2(texts_json)       <span class="cmt">-- Summarize collected texts</span>
llm_themes_2(texts_json, n)   <span class="cmt">-- Extract N themes</span>
llm_cluster_2(texts_json, n)  <span class="cmt">-- Cluster into N groups</span>
llm_consensus_2(texts_json)   <span class="cmt">-- Find common ground</span>
classify_single(text, opts)   <span class="cmt">-- Classify into options</span>

<span class="cmt">-- The rewriter converts high-level syntax to these:</span>
<span class="fn">SUMMARIZE</span>(col) → summarize_2(to_json(LIST(col)))
<span class="fn">THEMES</span>(col, <span class="num">5</span>) → llm_themes_2(to_json(LIST(col)), <span class="num">5</span>)</pre>
  </div>
</div>

<h3>UDF Registration</h3>

<p>
  When a DuckDB connection is created (either for PostgreSQL wire protocol or direct access),
  <code>register_rvbbit_udf(conn)</code> is called to register all UDFs:
</p>

<div class="code-block">
  <div class="code-block-header">
    <span class="code-block-lang python">UDF Registration (Simplified)</span>
  </div>
  <div class="code-block-content">
    <pre><span class="kw">def</span> register_rvbbit_udf(conn):
    <span class="cmt"># Core UDFs</span>
    conn.create_function(<span class="str">"rvbbit"</span>, rvbbit_impl, [...], <span class="str">"VARCHAR"</span>)
    conn.create_function(<span class="str">"rvbbit_cascade_udf"</span>, cascade_impl, [...], <span class="str">"VARCHAR"</span>)

    <span class="cmt"># Embedding UDFs</span>
    conn.create_function(<span class="str">"semantic_embed"</span>, embed_impl, [...], <span class="str">"DOUBLE[]"</span>)
    conn.create_function(<span class="str">"similar_to"</span>, similarity_impl, [...], <span class="str">"DOUBLE"</span>)

    <span class="cmt"># Aggregate UDFs</span>
    conn.create_function(<span class="str">"summarize_2"</span>, summarize_impl, [...], <span class="str">"VARCHAR"</span>)
    conn.create_function(<span class="str">"llm_themes_2"</span>, themes_impl, [...], <span class="str">"VARCHAR"</span>)

    <span class="cmt"># Dynamic registry-backed functions</span>
    register_dynamic_sql_functions(conn)</pre>
  </div>
</div>

<h2 id="sql-server">PostgreSQL Wire Protocol Server</h2>

<p>
  RVBBIT includes a PostgreSQL wire protocol server that lets you connect with any PostgreSQL
  client (DataGrip, DBeaver, psql, Python's psycopg2, etc.). Queries are processed through the
  full semantic SQL pipeline.
</p>

<h3>Starting the Server</h3>

<div class="code-block">
  <div class="code-block-header">
    <span class="code-block-lang bash">Server Commands</span>
  </div>
  <div class="code-block-content">
    <pre><span class="cmt"># Start the SQL server</span>
rvbbit serve sql --port <span class="num">15432</span>

<span class="cmt"># Or shorter alias</span>
rvbbit sql server --port <span class="num">15432</span>

<span class="cmt"># Connect with psql</span>
psql -h localhost -p <span class="num">15432</span> -U rvbbit -d rvbbit

<span class="cmt"># Connect with Python</span>
<span class="kw">import</span> psycopg2
conn = psycopg2.connect(host=<span class="str">"localhost"</span>, port=<span class="num">15432</span>, user=<span class="str">"rvbbit"</span>, dbname=<span class="str">"rvbbit"</span>)</pre>
  </div>
</div>

<h3>Session Architecture</h3>

<p>
  Each client connection gets an isolated DuckDB session:
</p>

<table>
  <thead>
    <tr>
      <th>Feature</th>
      <th>Behavior</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><strong>Session Isolation</strong></td>
      <td>Each connection gets its own DuckDB instance (in-memory or file-backed)</td>
    </tr>
    <tr>
      <td><strong>Database Routing</strong></td>
      <td><code>memory</code>/<code>default</code> = in-memory; others = <code>session_dbs/{name}.duckdb</code></td>
    </tr>
    <tr>
      <td><strong>UDF Registration</strong></td>
      <td>All UDFs registered automatically on connection</td>
    </tr>
    <tr>
      <td><strong>Lazy Attach</strong></td>
      <td>External databases attached on-demand when referenced</td>
    </tr>
    <tr>
      <td><strong>Cost Tracking</strong></td>
      <td>All UDF calls tracked to the session for analytics</td>
    </tr>
    <tr>
      <td><strong>Thread Safety</strong></td>
      <td>Each connection has its own thread with locked DuckDB access</td>
    </tr>
  </tbody>
</table>

<h3>Magic Tables</h3>

<p>
  The server provides access to RVBBIT's execution data through magic tables:
</p>

<div class="code-block">
  <div class="code-block-header">
    <span class="code-block-lang">Magic Tables</span>
  </div>
  <div class="code-block-content">
    <pre><span class="cmt">-- All execution logs</span>
<span class="kw">SELECT</span> session_id, cell_name, model, cost
<span class="kw">FROM</span> all_data
<span class="kw">WHERE</span> cost > <span class="num">0</span>
<span class="kw">ORDER BY</span> timestamp <span class="kw">DESC</span>
<span class="kw">LIMIT</span> <span class="num">100</span>;

<span class="cmt">-- Evaluation data from candidates</span>
<span class="kw">SELECT</span> *
<span class="kw">FROM</span> all_evals
<span class="kw">WHERE</span> cascade_id = <span class="str">'my_cascade'</span>;</pre>
  </div>
</div>

<h2 id="annotations">Annotation System</h2>

<p>
  Annotations let you modify semantic operator behavior without changing SQL syntax.
  They're SQL comments that the rewriter recognizes and processes.
</p>

<h3>Annotation Syntax</h3>

<div class="code-block">
  <div class="code-block-header">
    <span class="code-block-lang">Annotation Examples</span>
  </div>
  <div class="code-block-content">
    <pre><span class="cmt">-- @ use a fast model for this query</span>
<span class="kw">SELECT</span> * <span class="kw">FROM</span> docs
<span class="kw">WHERE</span> title <span class="fn">MEANS</span> <span class="str">'financial report'</span>;

<span class="cmt">-- @ threshold: 0.8</span>
<span class="kw">SELECT</span> * <span class="kw">FROM</span> articles
<span class="kw">WHERE</span> content <span class="fn">ABOUT</span> <span class="str">'sustainability'</span>;

<span class="cmt">-- @ candidates.factor: 3</span>
<span class="cmt">-- @ candidates.evaluator: human</span>
<span class="kw">SELECT</span> <span class="fn">SUMMARIZE</span>(feedback) <span class="kw">FROM</span> reviews;</pre>
  </div>
</div>

<h3>How Annotations Work</h3>

<p>
  The annotation parser extracts <code>-- @</code> comments and injects them into the criterion
  string passed to the cascade. The cascade's bodybuilder (request mode) parses these hints:
</p>

<div class="code-block">
  <div class="code-block-header">
    <span class="code-block-lang">Annotation Processing</span>
  </div>
  <div class="code-block-content">
    <pre><span class="cmt">-- Original</span>
<span class="cmt">-- @ use anthropic/claude-haiku</span>
<span class="kw">WHERE</span> title <span class="fn">MEANS</span> <span class="str">'urgent'</span>

<span class="cmt">-- Criterion becomes:</span>
<span class="str">"use anthropic/claude-haiku - urgent"</span>

<span class="cmt">-- The cascade instructions can then reference this</span></pre>
  </div>
</div>

<h3>Available Annotations</h3>

<table>
  <thead>
    <tr>
      <th>Annotation</th>
      <th>Effect</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code>-- @ free text</code></td>
      <td>Prepended to criterion (model hints, context)</td>
    </tr>
    <tr>
      <td><code>-- @ threshold: N</code></td>
      <td>Custom score threshold for ABOUT operators</td>
    </tr>
    <tr>
      <td><code>-- @ candidates.factor: N</code></td>
      <td>Run cascade N times, pick best result</td>
    </tr>
    <tr>
      <td><code>-- @ candidates.evaluator: human|llm</code></td>
      <td>Who picks the winning candidate</td>
    </tr>
    <tr>
      <td><code>-- @ candidates.mode: rank_all|pick_one</code></td>
      <td>Selection mode for candidates</td>
    </tr>
  </tbody>
</table>

<h2 id="caching">Caching Strategies</h2>

<p>
  RVBBIT uses multiple caching layers to minimize LLM calls and maximize performance.
</p>

<h3>Multi-Level Cache</h3>

<div class="code-block">
  <div class="code-block-header">
    <span class="code-block-lang">Cache Hierarchy</span>
  </div>
  <div class="code-block-content">
    <pre>┌─────────────────────────────────────────┐
│ Level 1: In-Memory (per connection)     │
│ - Fastest, not shared, ephemeral        │
│ - Hash: MD5(instructions | value)       │
└────────────────────┬────────────────────┘
                     │ miss
                     ▼
┌─────────────────────────────────────────┐
│ Level 2: ClickHouse (persistent)        │
│ - Survives restarts, shared across      │
│ - TTL support: '1d', '2h', '30m'        │
└────────────────────┬────────────────────┘
                     │ miss
                     ▼
┌─────────────────────────────────────────┐
│ Execute Cascade (LLM call)              │
│ - Store result in both L1 and L2        │
└─────────────────────────────────────────┘</pre>
  </div>
</div>

<h3>Structural Caching (Parsing Functions)</h3>

<p>
  Parsing functions use a special caching strategy that dramatically reduces LLM calls:
</p>

<div class="callout callout-tip">
  <div class="callout-title"><iconify-icon icon="mdi:flash"></iconify-icon> Code That Writes Code</div>
  <p>
    Instead of calling the LLM for every value, parsing functions:
  </p>
  <ol>
    <li>Analyze the <strong>shape</strong> of the input (e.g., <code>(DDD) DDD-DDDD</code> for phone)</li>
    <li>Generate a SQL expression (regex) to parse that shape</li>
    <li>Cache the SQL expression by shape fingerprint</li>
    <li>Future values with the same shape use cached SQL - zero LLM cost</li>
  </ol>
  <p>
    Parse a million phone numbers in 3 formats? That's 3 LLM calls, not a million.
  </p>
</div>

<h3>Cache Configuration</h3>

<p>
  Cascades can configure caching behavior in their <code>sql_function</code> block:
</p>

<div class="code-block">
  <div class="code-block-header">
    <span class="code-block-lang yaml">Cache Configuration</span>
  </div>
  <div class="code-block-content">
    <pre><span class="key">sql_function</span>:
  <span class="key">name</span>: my_operator
  <span class="key">cache</span>: <span class="kw">true</span>         <span class="cmt"># Enable caching (default: true)</span>
  <span class="key">cache_ttl</span>: <span class="str">"1d"</span>     <span class="cmt"># Time-to-live: 1d, 2h, 30m, 60s</span></pre>
  </div>
</div>

<h2 id="custom-operators">Creating Custom Operators</h2>

<p>
  The most powerful feature: define your own SQL operators using cascade files -
  <strong>no Python code required</strong>.
</p>

<h3>Operator Discovery</h3>

<p>
  At startup, RVBBIT scans these directories for cascade files with <code>sql_function</code> blocks:
</p>

<ul>
  <li><code>cascades/semantic_sql/*.cascade.yaml</code> - Built-in operators</li>
  <li><code>traits/semantic_sql/*.cascade.yaml</code> - User overrides</li>
</ul>

<h3>Cascade Structure</h3>

<div class="code-block">
  <div class="code-block-header">
    <span class="code-block-lang yaml">cascades/semantic_sql/my_operator.cascade.yaml</span>
  </div>
  <div class="code-block-content">
    <pre><span class="key">cascade_id</span>: my_custom_operator

<span class="cmt"># SQL function metadata - this is what makes it an operator</span>
<span class="key">sql_function</span>:
  <span class="key">name</span>: my_op                         <span class="cmt"># Function name in SQL</span>
  <span class="key">description</span>: <span class="str">Check if text has property X</span>
  <span class="key">args</span>:                                <span class="cmt"># Function arguments</span>
    - <span class="key">name</span>: text
      <span class="key">type</span>: VARCHAR
    - <span class="key">name</span>: criterion
      <span class="key">type</span>: VARCHAR
  <span class="key">returns</span>: BOOLEAN                    <span class="cmt"># Return type: VARCHAR, BOOLEAN, DOUBLE, JSON</span>
  <span class="key">shape</span>: SCALAR                       <span class="cmt"># SCALAR, AGGREGATE, or DIMENSION</span>
  <span class="key">operators</span>:                          <span class="cmt"># SQL syntaxes that trigger this</span>
    - <span class="str">"{{ text }} MY_OP {{ criterion }}"</span>        <span class="cmt"># Infix syntax</span>
    - <span class="str">"MY_OP({{ text }}, {{ criterion }})"</span>      <span class="cmt"># Function syntax</span>
  <span class="key">cache</span>: <span class="kw">true</span>
  <span class="key">cache_ttl</span>: <span class="str">"1h"</span>

<span class="cmt"># Implementation - just like any cascade</span>
<span class="key">cells</span>:
  - <span class="key">name</span>: evaluate
    <span class="key">model</span>: google/gemini-2.5-flash-lite   <span class="cmt"># Fast, cheap model</span>
    <span class="key">instructions</span>: |
      Determine if the following text has property "{{ input.criterion }}".

      TEXT: {{ input.text }}

      Answer with ONLY "true" or "false", nothing else.
    <span class="key">output_schema</span>:
      <span class="key">type</span>: boolean</pre>
  </div>
</div>

<h3>Operator Patterns</h3>

<p>
  The <code>operators</code> list defines SQL syntaxes that trigger the cascade. Patterns use
  Jinja2 template syntax with argument names:
</p>

<table>
  <thead>
    <tr>
      <th>Pattern Type</th>
      <th>Example Pattern</th>
      <th>SQL Usage</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Infix (word)</td>
      <td><code>{{ text }} MEANS {{ criterion }}</code></td>
      <td><code>title MEANS 'report'</code></td>
    </tr>
    <tr>
      <td>Infix (symbol)</td>
      <td><code>{{ a }} ~ {{ b }}</code></td>
      <td><code>col1 ~ col2</code></td>
    </tr>
    <tr>
      <td>Function</td>
      <td><code>SCORE({{ text }}, {{ criterion }})</code></td>
      <td><code>SCORE(title, 'urgent')</code></td>
    </tr>
    <tr>
      <td>Multi-word</td>
      <td><code>{{ text }} RELEVANCE TO {{ query }}</code></td>
      <td><code>content RELEVANCE TO 'ML'</code></td>
    </tr>
    <tr>
      <td>Postfix</td>
      <td><code>{{ text }} SENTIMENT_SCORE</code></td>
      <td><code>review SENTIMENT_SCORE</code></td>
    </tr>
  </tbody>
</table>

<h3>Complete Example: Sentiment Score Operator</h3>

<div class="code-block">
  <div class="code-block-header">
    <span class="code-block-lang yaml">cascades/semantic_sql/sentiment_score.cascade.yaml</span>
  </div>
  <div class="code-block-content">
    <pre><span class="key">cascade_id</span>: semantic_sentiment_score
<span class="key">description</span>: <span class="str">Score text sentiment from -1.0 to +1.0</span>

<span class="key">sql_function</span>:
  <span class="key">name</span>: sentiment_score
  <span class="key">description</span>: <span class="str">Returns sentiment score from -1.0 (negative) to +1.0 (positive)</span>
  <span class="key">args</span>:
    - <span class="key">name</span>: text
      <span class="key">type</span>: VARCHAR
  <span class="key">returns</span>: DOUBLE
  <span class="key">shape</span>: SCALAR
  <span class="key">operators</span>:
    - <span class="str">"SENTIMENT_SCORE({{ text }})"</span>
    - <span class="str">"{{ text }} SENTIMENT_SCORE"</span>
  <span class="key">cache</span>: <span class="kw">true</span>

<span class="key">cells</span>:
  - <span class="key">name</span>: score
    <span class="key">model</span>: google/gemini-2.5-flash-lite
    <span class="key">instructions</span>: |
      Analyze the sentiment of this text and return a score.

      TEXT: {{ input.text }}

      Return a JSON object with a single "score" field:
      - Score ranges from -1.0 (very negative) to +1.0 (very positive)
      - 0.0 is neutral

      Example: {"score": 0.7}
    <span class="key">output_schema</span>:
      <span class="key">score</span>: number</pre>
  </div>
</div>

<p>Now use it in SQL:</p>

<div class="code-block">
  <div class="code-block-header">
    <span class="code-block-lang">Using Custom Operator</span>
  </div>
  <div class="code-block-content">
    <pre><span class="cmt">-- Function syntax</span>
<span class="kw">SELECT</span>
  product_id,
  <span class="kw">AVG</span>(<span class="fn">SENTIMENT_SCORE</span>(review_text)) <span class="kw">AS</span> avg_sentiment
<span class="kw">FROM</span> reviews
<span class="kw">GROUP BY</span> product_id
<span class="kw">HAVING</span> avg_sentiment < <span class="num">-0.3</span>;

<span class="cmt">-- Postfix syntax</span>
<span class="kw">SELECT</span> review_text, review_text <span class="fn">SENTIMENT_SCORE</span> <span class="kw">AS</span> sentiment
<span class="kw">FROM</span> reviews
<span class="kw">ORDER BY</span> sentiment <span class="kw">DESC</span>;</pre>
  </div>
</div>

<h2 id="map-run">RVBBIT MAP/RUN Statements</h2>

<p>
  Execute cascades directly in SQL, either mapping over rows or running once with all data.
</p>

<h3>RVBBIT MAP</h3>

<p>
  Execute a cascade once per row in the result set:
</p>

<div class="code-block">
  <div class="code-block-header">
    <span class="code-block-lang">RVBBIT MAP Syntax</span>
  </div>
  <div class="code-block-content">
    <pre><span class="cmt">-- Basic MAP: run cascade for each row</span>
<span class="kw">RVBBIT MAP</span> process_order(<span class="str">'{{ order_id }}'</span>, <span class="str">'{{ email }}'</span>)
<span class="kw">FROM</span> (
  <span class="kw">SELECT</span> order_id, email
  <span class="kw">FROM</span> orders
  <span class="kw">WHERE</span> status = <span class="str">'pending'</span>
  <span class="kw">LIMIT</span> <span class="num">100</span>
);

<span class="cmt">-- With output column selection</span>
<span class="kw">RVBBIT MAP</span> enrich_customer(<span class="str">'{{ customer_id }}'</span>)
<span class="kw">RETURNING</span> enriched_data, confidence_score
<span class="kw">FROM</span> customers;</pre>
  </div>
</div>

<h3>RVBBIT RUN</h3>

<p>
  Execute a cascade once with the entire result set as JSON:
</p>

<div class="code-block">
  <div class="code-block-header">
    <span class="code-block-lang">RVBBIT RUN Syntax</span>
  </div>
  <div class="code-block-content">
    <pre><span class="cmt">-- Basic RUN: cascade receives all rows as JSON</span>
<span class="kw">RVBBIT RUN</span> analyze_trends(<span class="str">'{{ results }}'</span>)
<span class="kw">FROM</span> (
  <span class="kw">SELECT</span> date, revenue, region
  <span class="kw">FROM</span> sales
  <span class="kw">WHERE</span> date >= <span class="str">'2024-01-01'</span>
);

<span class="cmt">-- With temp table (cascade can query it)</span>
<span class="kw">RVBBIT RUN</span> complex_analysis
<span class="kw">USING</span> <span class="kw">SELECT</span> * <span class="kw">FROM</span> metrics <span class="kw">WHERE</span> date > <span class="str">'2024-01-01'</span>
<span class="kw">INTO</span> results_table;</pre>
  </div>
</div>

<h3>MAP vs RUN</h3>

<table>
  <thead>
    <tr>
      <th>Statement</th>
      <th>Cascade Calls</th>
      <th>Data Access</th>
      <th>Use Case</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code>RVBBIT MAP</code></td>
      <td>Once per row</td>
      <td>Row values via Jinja2</td>
      <td>Per-row enrichment, notifications, processing</td>
    </tr>
    <tr>
      <td><code>RVBBIT RUN</code></td>
      <td>Once total</td>
      <td>All rows as JSON or temp table</td>
      <td>Aggregate analysis, trend detection, reporting</td>
    </tr>
  </tbody>
</table>

<h3>RVBBIT EMBED</h3>

<p>
  Create embeddings for vector search:
</p>

<div class="code-block">
  <div class="code-block-header">
    <span class="code-block-lang">RVBBIT EMBED Syntax</span>
  </div>
  <div class="code-block-content">
    <pre><span class="cmt">-- Index a column for vector search</span>
<span class="kw">RVBBIT EMBED</span> articles.content
<span class="kw">FROM</span> articles
<span class="kw">WHERE</span> published = <span class="kw">true</span>;

<span class="cmt">-- With options</span>
<span class="kw">RVBBIT EMBED</span> documents.summary
<span class="kw">FROM</span> documents
<span class="kw">WITH</span> (
  model = <span class="str">'qwen/qwen3-embedding-8b'</span>,
  batch_size = <span class="num">100</span>
);</pre>
  </div>
</div>

<h2 id="best-practices">Best Practices</h2>

<h3>Performance</h3>

<div class="callout callout-warning">
  <div class="callout-title"><iconify-icon icon="mdi:alert-outline"></iconify-icon> LLM Call Costs</div>
  <p>
    Semantic operators call LLMs. For large datasets:
  </p>
  <ul>
    <li>Apply <code>WHERE</code> and <code>LIMIT</code> to reduce row count</li>
    <li>Use <code>SIMILAR_TO</code> (embedding-based) instead of <code>MEANS</code> (LLM-based) when possible</li>
    <li>Leverage caching - repeated values hit cache</li>
    <li>Use dimension functions (<code>TOPICS()</code>) instead of scalar classification for GROUP BY</li>
  </ul>
</div>

<h3>Query Design</h3>

<ul>
  <li><strong>Filter first</strong>: Apply traditional filters before semantic operators</li>
  <li><strong>Use scores for ranking</strong>: <code>SCORE()</code> + <code>ORDER BY</code> is often better than <code>MEANS</code> + <code>WHERE</code></li>
  <li><strong>Batch with GROUP BY</strong>: Aggregate functions process all values in one LLM call</li>
  <li><strong>Cache-friendly criteria</strong>: Consistent criterion strings improve cache hit rates</li>
</ul>

<h3>Debugging</h3>

<div class="code-block">
  <div class="code-block-header">
    <span class="code-block-lang">Debugging Queries</span>
  </div>
  <div class="code-block-content">
    <pre><span class="cmt">-- Check what your query rewrites to</span>
<span class="kw">EXPLAIN</span> <span class="kw">SELECT</span> * <span class="kw">FROM</span> docs <span class="kw">WHERE</span> title <span class="fn">MEANS</span> <span class="str">'report'</span>;

<span class="cmt">-- View recent UDF calls and costs</span>
<span class="kw">SELECT</span> session_id, cell_name, model, cost, duration_ms
<span class="kw">FROM</span> all_data
<span class="kw">WHERE</span> is_sql_udf = <span class="kw">true</span>
<span class="kw">ORDER BY</span> timestamp <span class="kw">DESC</span>
<span class="kw">LIMIT</span> <span class="num">20</span>;

<span class="cmt">-- Check cache hit rates</span>
<span class="kw">SELECT</span>
  udf_type,
  <span class="kw">COUNT</span>(*) <span class="kw">AS</span> calls,
  <span class="kw">SUM</span>(<span class="kw">CASE WHEN</span> cache_hit <span class="kw">THEN</span> <span class="num">1</span> <span class="kw">ELSE</span> <span class="num">0</span> <span class="kw">END</span>) <span class="kw">AS</span> hits
<span class="kw">FROM</span> sql_query_log
<span class="kw">GROUP BY</span> udf_type;</pre>
  </div>
</div>

<hr>

<h2>Next Steps</h2>

<ul>
  <li><a href="#operators" data-link>Built-in Operators</a> - Complete reference for all 50+ operators</li>
  <li><a href="#embedding" data-link>Vector Search & Embedding</a> - Embedding details and SIMILAR_TO usage</li>
  <li><a href="#cell-types" data-link>Cell Types</a> - Using SQL cells in cascades</li>
  <li><a href="#tools" data-link>Tools Reference</a> - <code>sql_data</code> and related tools</li>
</ul>
