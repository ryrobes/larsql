cascade_id: artifact_workflow_demo
description: |
  Demonstrates the complete artifact workflow:
  1. Iterate on visualizations with request_decision (HTMX blocking)
  2. Publish final polished version with create_artifact (persistent)

  Shows how artifacts become permanent gallery items while request_decision
  is ephemeral iteration tool.

inputs_schema:
  dataset_name: "What dataset to analyze"

memory: artifact_test

phases:
  - name: draft_and_iterate
    tackle:
      - request_decision
      - create_artifact
      - route_to
      - run_code
      - linux_shell
      - sql_search
      #- list_sql_connections
      - request_decision
      - sql_query
    #model: anthropic/claude-sonnet-4.5
    handoffs:
      - finalize
    soundings:
      factor: 3
      models:
        - x-ai/grok-4.1-fast
        #- openai/gpt-5.2
        #- google/gemini-3-pro-preview
    rules:
      max_turns: 10
    instructions: |
      Analyze / find dataset: {{ input.dataset_name }}

      ## Workflow (Each Sounding Explores Different Visualizations):

      1. **Get Data (you have many tools at your command)

      2. **Create a professional and data-dense Dashboard**

      3. **Request approval** using request_decision with HTMX:
         - Show your unique visualization
         - Ask: "Does this visualization effectively show the data?"
         - Buttons: "Approve" or "Request Changes"

      4. **If approved:** Use create_artifact to publish, and then route_to the finalize step.

  - name: finalize
    tackle: ["create_artifact"]
    instructions: |
      Artifact created: {{ outputs.draft_and_iterate.artifact_id }}
      (Please create it, if not done already)

      Provide a summary of:
      - What the artifact contains
      - Key insights from the data
      - How to access it (Artifacts gallery)

    context:
      from: [draft_and_iterate]
