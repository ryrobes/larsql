cascade_id: comprehensive_test
description: "Comprehensive test: deterministic data, LLM soundings, validation, decision points, artifacts"
inputs_schema:
  analysis_type: "Type of analysis (sales/customer/product)"

phases:
  # ========================================================================
  # PHASE 1: Deterministic SQL Data Extraction
  # ========================================================================
  - name: extract_sales_data
    tool: sql_data
    inputs:
      query: |
        -- Generate sample sales data
        SELECT * FROM (
          VALUES
            ('2024-12-01', 'Electronics', 'Laptop', 1200, 5),
            ('2024-12-02', 'Electronics', 'Phone', 800, 12),
            ('2024-12-03', 'Clothing', 'Jacket', 150, 25),
            ('2024-12-04', 'Home', 'Chair', 300, 8),
            ('2024-12-05', 'Electronics', 'Tablet', 600, 15),
            ('2024-12-06', 'Clothing', 'Shoes', 120, 30),
            ('2024-12-07', 'Home', 'Desk', 450, 6),
            ('2024-12-08', 'Electronics', 'Headphones', 200, 20)
        ) AS sales(date, category, product, price, quantity)
    handoffs:
      - enrich_data

  # ========================================================================
  # PHASE 2: Deterministic Python Enrichment
  # ========================================================================
  - name: enrich_data
    tool: python_data
    inputs:
      code: |
        import pandas as pd

        # Access prior phase data (zero-copy from temp table!)
        df = data.extract_sales_data

        # Calculate metrics
        df['revenue'] = df['price'] * df['quantity']
        df['profit_margin'] = df['category'].map({
            'Electronics': 0.15,
            'Clothing': 0.40,
            'Home': 0.25
        })
        df['profit'] = df['revenue'] * df['profit_margin']
        df['date'] = pd.to_datetime(df['date'])

        # Performance classification
        df['tier'] = pd.cut(df['revenue'],
                            bins=[0, 2000, 5000, float('inf')],
                            labels=['Low', 'Medium', 'High'])

        result = df
        # Auto-creates temp table: _enrich_data
    handoffs:
      - analyze_with_soundings

  # ========================================================================
  # PHASE 3: LLM Analysis with Soundings (3 parallel attempts)
  # ========================================================================
  - name: analyze_with_soundings
    instructions: |
      Analyze the sales data and provide business insights.

      Focus: {{ input.analysis_type }}

      You can query the enriched data from temp table _enrich_data.

      Provide structured analysis as JSON:
      {
        "key_insights": ["insight 1", "insight 2", "insight 3"],
        "top_performers": ["product/category with metrics"],
        "recommendations": ["actionable rec 1", "actionable rec 2"],
        "confidence": 0.85
      }

      Be specific - reference actual products, categories, and numbers.
    tackle:
      - set_state
    soundings:
      factor: 3
      mode: evaluate
      evaluator_instructions: |
        Pick the most data-driven and actionable analysis.

        Criteria:
        - References specific products/categories from the data
        - Uses actual numbers (not generic percentages)
        - Recommendations are concrete and achievable

        Return: {"winner_index": 0, "reason": "why this one is best"}
    output_schema:
      type: object
      required: ["key_insights", "top_performers", "recommendations", "confidence"]
      properties:
        key_insights:
          type: array
          items: {type: string}
          minItems: 3
        top_performers:
          type: array
          items: {type: string}
          minItems: 1
        recommendations:
          type: array
          items: {type: string}
          minItems: 2
        confidence:
          type: number
          minimum: 0
          maximum: 1
    handoffs:
      - validate_analysis

  # ========================================================================
  # PHASE 4: Validation with Repair Loop
  # ========================================================================
  - name: validate_analysis
    instructions: |
      Validate and refine the business analysis.

      Analysis: {{ outputs.analyze_with_soundings }}

      Check:
      1. Do insights reference actual products from our data? (Laptop, Phone, Jacket, Chair, Tablet, Shoes, Desk, Headphones)
      2. Are recommendations specific and achievable?
      3. Is the confidence score reasonable given depth of analysis?

      If issues found: revise the analysis.
      If all good: confirm validation passed.

      Output same JSON structure with added field:
      {
        "key_insights": [...],
        "top_performers": [...],
        "recommendations": [...],
        "confidence": 0.XX,
        "validation_status": "passed" or "revised",
        "validation_notes": "what you checked/changed"
      }
    tackle:
      - set_state
    rules:
      max_turns: 1
      max_attempts: 3
      loop_until: satisfied
      loop_until_prompt: "Ensure validation_status is explicitly set to 'passed' to confirm validation succeeded"
    output_schema:
      type: object
      required: ["key_insights", "recommendations", "confidence", "validation_status"]
    handoffs:
      - request_approval

  # ========================================================================
  # PHASE 5: Decision Point (Human Interrupt with Timeout)
  # ========================================================================
  - name: request_approval
    instructions: |
      Request human approval before publishing.

      Validated analysis:
      {{ outputs.validate_analysis | tojson(indent=2) }}

      Output a decision block asking for approval:

      <decision>
      {
        "question": "Publish this analysis as an artifact?",
        "context": "Analysis passed validation. Review findings and recommendations above.",
        "severity": "info",
        "options": [
          {
            "id": "publish",
            "label": "Publish Now",
            "description": "Create artifact and complete",
            "style": "primary"
          },
          {
            "id": "skip",
            "label": "Skip Publishing",
            "description": "Complete without artifact",
            "style": "secondary"
          }
        ]
      }
      </decision>
    decision_points:
      enabled: true
      trigger: output
      timeout_seconds: 60
      routing:
        publish: create_dashboard
        skip: finalize
        _timeout: create_dashboard
    tackle:
      - route_to

  # ========================================================================
  # PHASE 6: Create Artifact (if approved)
  # ========================================================================
  - name: create_dashboard
    instructions: |
      Create an interactive HTML dashboard artifact.

      Analysis data: {{ outputs.validate_analysis }}

      Use create_artifact to publish a dashboard titled "Sales Analysis Report".

      Include:
      - Key insights in a card grid
      - Top performers list
      - Recommendations section
      - Dark theme (#0a0a0a background, #60a5fa accents)

      Keep it simple - focus on readability.
    tackle:
      - create_artifact
      - set_state
    handoffs:
      - finalize

  # ========================================================================
  # PHASE 7: Finalize
  # ========================================================================
  - name: finalize
    instructions: |
      Cascade complete! Summarize what was accomplished.

      {% if outputs.create_dashboard %}
      ✓ Published artifact
      {% else %}
      ℹ️  Skipped artifact publishing
      {% endif %}

      Analysis results: {{ outputs.validate_analysis.validation_status }}
    tackle:
      - set_state
