# SQL Chart Generation Analysis - Full Evolution
# Auto-discovers interesting data questions, executes SQL queries,
# creates charts, iterates on them, and presents findings.
#
# FIXES (v4):
# - Removed set_state (unnecessary - outputs flow via context)
# - Removed {{ state.question }} references
# - Added loop_until validators for per-turn early exit
# - Added max_turns to phases that may need iteration
# - Uses loop_until_silent to avoid gaming validators
# - mutate: false (dynamic questions not useful for A/B learning)
# - Uses inline validators (v4) - validators defined in cascade instead of separate files

cascade_id: sql_chart_gen_analysis_full_y1

description: >
  Auto-discovers interesting data questions, executes SQL queries,
  creates charts, iterates on them, and presents findings.

inputs_schema:
  focus_area: "(Optional) Area of interest to focus the analysis on, e.g. 'geographic trends', 'time patterns', 'outliers'"

memory: sql_rag_search

# Inline validators - defined here instead of separate files in tackle/
# These are checked first when resolving validator names in loop_until
validators:
  question_formulated:
    instructions: |
      Check if this output contains a clearly formulated analytical question.

      Output to check:
      {{ input.content }}

      A VALID output must have:
      1. A clear analytical question (often marked with "**Question:**" or similar)
      2. The question should be specific (not vague like "analyze the data")
      3. The question should be answerable with SQL (involves data, patterns, comparisons)

      Return JSON only:
      - If valid: {"valid": true, "reason": "Question clearly stated: [brief summary]"}
      - If not valid: {"valid": false, "reason": "No clear question or question is too vague"}

  schema_discovered:
    instructions: |
      Check if this output contains discovered schema information for the analytical question.

      Output to check:
      {{ input.content }}

      A VALID output must have:
      1. Reference to specific table(s) that will be used
      2. Column names mentioned (at least the key columns needed)
      3. Some indication of data types or sample values

      Return JSON only:
      - If valid: {"valid": true, "reason": "Schema found: [table names]"}
      - If not valid: {"valid": false, "reason": "Missing table/column information"}

  query_executed:
    instructions: |
      Check if a SQL query was successfully executed with results.

      Output to check:
      {{ input.content }}

      A VALID output must have:
      1. A SQL query that was executed (SELECT statement visible)
      2. Results returned (data rows, counts, or aggregates)
      3. NO error messages like "syntax error", "table not found", "column does not exist"

      Signs of SUCCESS:
      - Data rows displayed
      - Counts or statistics shown
      - "rows returned" or similar

      Signs of FAILURE:
      - SQL errors
      - "failed", "error", "invalid"
      - Empty results with no explanation

      Return JSON only:
      - If valid: {"valid": true, "reason": "Query executed successfully with results"}
      - If not valid: {"valid": false, "reason": "Query failed or no results: [brief description]"}

  analysis_complete:
    instructions: |
      Check if this output contains a complete data analysis.

      Output to check:
      {{ input.content }}

      A VALID output must have:
      1. The original question being answered
      2. The SQL query used
      3. A data sample or summary of results
      4. Key findings with specific numbers/percentages

      Return JSON only:
      - If valid: {"valid": true, "reason": "Complete analysis with findings"}
      - If not valid: {"valid": false, "reason": "Missing [question/query/data/findings]"}

  chart_rendered:
    instructions: |
      Check if a chart was successfully rendered (not whether it's good, just that it exists).

      Output to check:
      {{ input.content }}

      A VALID output must have:
      1. Evidence of a chart being created (mentions of image, chart, visualization being generated)
      2. NO rendering errors, spec errors, or validation failures
      3. NO messages like "error", "failed to render", "invalid spec", "schema validation failed"

      Signs of SUCCESS:
      - "Chart created", "Image generated", "Here is the visualization"
      - References to analyzing the chart visually
      - Discussion of what the chart shows

      Signs of FAILURE:
      - "Error", "Failed", "Invalid", "Could not render"
      - Vega-Lite or Plotly spec validation errors
      - Empty or missing chart output

      Return JSON only:
      - If valid: {"valid": true, "reason": "Chart rendered successfully"}
      - If not valid: {"valid": false, "reason": "No chart or rendering error: [brief description]"}

phases:
  # Phase 1: Discover an interesting analytical question
  - name: discover_question
    instructions: |
      Your goal is to explore the available data and come up with an INTERESTING analytical question to investigate.

      {% if input.focus_area %}Focus area hint: {{ input.focus_area }}{% endif %}

      **Step 1: Discover what data is available**
      Use `list_sql_connections` to see available data sources.
      Use `sql_search` with broad terms to discover tables (e.g., 'sales', 'users', 'events', or just browse what's there).

      **Step 2: Sample the data (DO NOT read everything!)**
      Once you find interesting tables, use `sql_query` to get SMALL SAMPLES:
      - `SELECT * FROM connection.table LIMIT 5` to see structure
      - `SELECT COUNT(*) FROM connection.table` for size
      - `SELECT DISTINCT column FROM connection.table LIMIT 20` to see categorical values
      - `SELECT column, COUNT(*) FROM connection.table GROUP BY column LIMIT 10` for distributions

      **Step 3: Formulate an interesting question**
      Based on what you discovered, come up with a question that:
      - Is answerable with the data available
      - Would produce an interesting visualization
      - Reveals patterns, trends, comparisons, or anomalies
      - Is specific enough to be actionable

      Good questions often involve:
      - Comparisons ("Which X has the highest Y?")
      - Trends over time ("How has X changed over time?")
      - Distributions ("What is the distribution of X across Y?")
      - Correlations ("Is there a relationship between X and Y?")
      - Outliers ("What are the unusual cases of X?")

      **End your response by clearly stating the question you've chosen to investigate.**
      Format it as: "**Question:** [Your specific analytical question here]"

    tackle:
      - sql_search
      #- list_sql_connections
      - request_decision
      #- sql_query

    soundings:
      factor: 6
      evaluator_instructions: |
        Evaluate question discovery attempts based on:

        1. **Question Quality** (40%): Is the question interesting, specific, and likely to produce insightful analysis?
        2. **Data Fit** (30%): Is the question well-suited to the available data? Can it actually be answered?
        3. **Visualization Potential** (20%): Would answering this question produce a compelling chart?
        4. **Exploration Quality** (10%): Did they efficiently sample the data without over-reading?

        Select the attempt that:
        - Formulated the MOST interesting and insightful question
        - Demonstrated efficient data exploration (sampling, not bulk reading)
        - Chose a question that's specific enough to be actionable
        - Clearly stated the question at the end of their response

        Prefer questions about trends, comparisons, distributions, or anomalies over simple counts or lists.
      models:
        #- anthropic/claude-sonnet-4.5
        - x-ai/grok-4.1-fast
        #- amazon/nova-premier-v1
        #- openai/gpt-5.1
        #- openai/gpt-4.1
        - openai/gpt-5.2
        #- anthropic/claude-opus-4.5
        - google/gemini-3-pro-preview
      mutate: false
      model_strategy: round-robin

    rules:
      max_turns: 3
      loop_until: question_formulated
      loop_until_silent: true

    handoffs:
      - discover_schema

  # Phase 2: Focused schema discovery
  - name: discover_schema
    instructions: |
      Review the question that was chosen in the previous phase. That question is what we're investigating.

      Now do a focused schema discovery to find the exact tables and columns needed to answer it.

      Use sql_search to find relevant tables that contain data to answer this question.

      Search for tables using natural language - the tool will return schema information including:
      - Column names and types
      - Value distributions for categorical columns
      - Sample rows
      - Row counts

      Analyze the results and identify which table(s) would be most useful.
      Note: the search data is ephemeral, so if you need access to it later please include important parts in your reply.

      **Restate the question and the relevant schema information you found.**

    context:
      from:
        - previous

    tackle:
      - sql_search
      - list_sql_connections
      - request_decision

    soundings:
      factor: 6
      evaluator_instructions: |
        Evaluate schema discovery attempts based on:

        1. **Relevance** (40%): Did they find tables that directly answer the question from the previous phase?
        2. **Thoroughness** (30%): Did they examine multiple relevant tables and understand the schema structure?
        3. **Data Understanding** (20%): Do they demonstrate understanding of column types, value distributions, and data quality?
        4. **Actionability** (10%): Did they provide clear next steps for query writing, including specific column names and table references?

        Select the attempt that:
        - Found the MOST relevant table(s) for the question
        - Demonstrated deepest understanding of the data structure
        - Provided most useful information for the next phase (query writing)
        - Avoided irrelevant tables while being thorough

        Prefer attempts that balance breadth (checking multiple options) with depth (understanding what's useful).
      models:
        #- anthropic/claude-sonnet-4.5
        - x-ai/grok-4.1-fast
        #- amazon/nova-premier-v1
        #- openai/gpt-5.1
        #- openai/gpt-4.1
        - openai/gpt-5.2
        #- anthropic/claude-opus-4.5
        - google/gemini-3-pro-preview
      mutate: false
      model_strategy: round-robin

    rules:
      max_turns: 2
      loop_until: schema_discovered
      loop_until_silent: true

    handoffs:
      - write_query

  # Phase 3: Write and execute SQL query
  - name: write_query
    instructions: |
      Based on the question and schema information from the previous phases, write a SQL query to answer the analytical question.

      Use the sql_query tool to execute your query.

      IMPORTANT Query Syntax:
      - CSV folders: SELECT * FROM connection_name.table_name
      - PostgreSQL/MySQL: SELECT * FROM connection_name.schema.table
      - Example: SELECT * FROM csv_files.bigfoot_sightings WHERE state = 'California'

      The schema info from the previous phase shows you:
      - Exact column names
      - Data types
      - Sample values (use these to understand the data format)
      - Value distributions (shows you what values exist in categorical columns)

      Write a clear, efficient query based on this information.

      **Include the question, your query, and the results in your response.**

    context:
      from:
        - previous

    tackle:
      - sql_query
      - request_decision

    soundings:
      factor: 6
      evaluator_instructions: |
        Evaluate SQL query attempts based on:

        1. **Correctness** (40%): Does the query execute without errors and return results?
        2. **Accuracy** (30%): Do the results actually answer the question?
        3. **Efficiency** (15%): Is the query optimized (proper filters, aggregations, no unnecessary data)?
        4. **Completeness** (15%): Does it return all relevant data needed to answer the question?

        Select the attempt that:
        - Executed successfully (queries with errors are automatic losers)
        - Returns the MOST relevant data for the question
        - Uses proper SQL syntax for the connection type
        - Applies appropriate filters, aggregations, or joins
        - Returns a reasonable amount of data (not too little, not too much)

        CRITICAL: Syntax errors or failed queries should be heavily penalized. A working query that's slightly less optimal is better than a perfect-looking query that fails.

        Prefer queries that demonstrate understanding of the schema and make smart decisions about what columns/rows to include.
      models:
        #- anthropic/claude-sonnet-4.5
        - x-ai/grok-4.1-fast
        #- amazon/nova-premier-v1
        #- openai/gpt-5.1
        #- openai/gpt-4.1
        - openai/gpt-5.2
        #- anthropic/claude-opus-4.5
        - google/gemini-3-pro-preview
      mutate: false
      model_strategy: round-robin

    rules:
      max_turns: 3
      loop_until: query_executed
      loop_until_silent: true

    handoffs:
      - analyze_results

  # Phase 4: Analyze query results
  - name: analyze_results
    instructions: |
      Analyze the query results from the previous phase and provide a clear answer to the analytical question.

      Summarize:
      - Key findings from the data
      - Any interesting patterns or insights
      - Direct answer to the question

      Be specific and reference actual numbers from the results.

      **IMPORTANT: Include the original question, the SQL query, and a representative sample of the data in your response - enough context so a chart could be constructed from the data.**

    context:
      from:
        - previous

    tackle: []

    soundings:
      factor: 6
      evaluator_instructions: |
        Evaluate data analysis attempts based on:

        1. **Accuracy** (35%): Does the analysis correctly interpret the query results?
        2. **Insight Quality** (30%): Does it identify meaningful patterns, trends, or anomalies?
        3. **Specificity** (20%): Does it reference actual numbers, percentages, or concrete evidence from the data?
        4. **Clarity** (15%): Is the answer clear, well-structured, and directly addresses the question?

        Select the attempt that:
        - Provides the MOST insightful interpretation of the data
        - Directly and clearly answers the original question
        - Supports claims with specific numbers/evidence from the results
        - Identifies interesting patterns beyond just the obvious
        - Avoids vague or generic statements
        - Demonstrates quantitative thinking (percentages, comparisons, trends)
        - Includes the SQL query and data sample for chart construction

        Prefer analyses that go beyond surface-level observations and provide actionable insights. An analysis that says "Sales increased by 47% in Q3, primarily driven by the Northeast region (23% growth)" is better than "Sales went up."

        Penalize attempts that:
        - Make claims not supported by the data
        - Are too vague or generic
        - Miss obvious patterns in the results
        - Don't directly answer the question
        - Don't include enough context for chart creation
      models:
        #- anthropic/claude-sonnet-4.5
        - x-ai/grok-4.1-fast
        #- amazon/nova-premier-v1
        #- openai/gpt-5.1
        #- openai/gpt-4.1
        - openai/gpt-5.2
        #- anthropic/claude-opus-4.5
        - google/gemini-3-pro-preview
      mutate: false
      model_strategy: round-robin

    rules:
      max_turns: 2
      loop_until: analysis_complete
      loop_until_silent: true

    handoffs:
      - create_initial_chart

  # Phase 5: Create initial chart with self-analysis
  # Uses loop_until to retry if chart rendering fails (spec errors, etc.)
  - name: create_initial_chart
    instructions: |
      Create a chart based on the data and analysis from the previous phase to help illustrate the findings.

      Use the create_vega_lite or create_plotly tool. After creating it, the image will be automatically injected for you to see.

      Once you see the chart image, analyze it against the requirements and describe:
      1. What you observe visually
      2. How well it meets the requirements
      3. What specific improvements are needed - does it help to answer the question? If multiple compound charts would help visualize, go for that. For styling use dark mode and give it some flair and personality.

      If you encounter a rendering error, fix the spec and try again.

    context:
      from:
        - previous

    tackle:
      - sql_query
      - create_vega_lite
      - create_plotly
      - request_decision

    soundings:
      factor: 6
      evaluator_instructions: |
        Evaluate based on:
        1. Accuracy of visual observations about the chart
        2. Depth of analysis against requirements
        3. Specificity of improvement suggestions

        Select the analysis that is most detailed and actionable. Must have successfully generated chart images to be valid.
      models:
        #- anthropic/claude-sonnet-4.5
        - x-ai/grok-4.1-fast
        #- amazon/nova-premier-v1
        #- openai/gpt-5.1
        #- openai/gpt-4.1
        - openai/gpt-5.2
        #- anthropic/claude-opus-4.5
        - google/gemini-3-pro-preview
      mutate: false
      model_strategy: round-robin
      reforge:
        steps: 2
        honing_prompt: |
          You previously analyzed this chart. Looking at the chart image again, provide even MORE specific improvements:

          - Exact color codes for better contrast (hex values)
          - Precise font sizes for labels
          - Specific axis range adjustments
          - Data point annotation placement
          - Are things being overlapped or clipped?
          - Legend positioning coordinates

          Be EXTREMELY specific and actionable. Reference exact elements you see in the image.
        factor_per_step: 2
        mutate: false
        evaluator_override: |
          Evaluate refinements on:
          1. Specificity (exact values, not vague suggestions)
          2. Visual awareness (referencing actual chart elements)
          3. Implementation feasibility
          4. Completeness of improvements

          Pick the most production-ready, implementable analysis.

    rules:
      max_turns: 3
      loop_until: chart_rendered
      loop_until_silent: true

    handoffs:
      - say_summary_summarize

  # Phase 6: Present summary to user
  - name: say_summary_summarize
    model: anthropic/claude-sonnet-4.5
    instructions: |
      Use the `say` tool to speak to the user and give a VERY short summary of the findings and chart. Persona is a sassy, foul mouthed, street kid turned corpo. Yet a beautiful vixen, none the less.

    context:
      from:
        - all

    tackle:
      - say

    rules:
      max_turns: 1
