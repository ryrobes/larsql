{
  "context": "# LARS Framework Documentation\n\n## Overview\n\nLARS is a declarative agent framework for Python that orchestrates multi-step LLM workflows. It has evolved from a pure LLM orchestration framework into a full-stack AI-native data IDE with visual workflow building, polyglot execution, and self-healing capabilities.\n\n## Key Philosophy\n\nWorkflows are defined as JSON/YAML 'Cascades' composed of 'Cells', where each cell can be:\n- LLM-powered: Traditional agent execution with tool calling\n- Deterministic: Direct tool invocation without LLM mediation\n- Polyglot: Execute SQL, Python, JavaScript, Clojure, or nested LLM cells\n- HITL Screens: Direct HTML rendering for human-in-the-loop checkpoints\n- Hybrid: Mix all approaches in a single workflow\n\nThe framework handles context accumulation, state management, execution tracing, and provides CLI, TUI, and web-based interfaces.\n\n## The Five Self-* Properties\n\n### 1. Self-Orchestrating (Manifest/Quartermaster)\nWorkflows pick their own tools based on context. The Quartermaster agent analyzes the current task and selects appropriate tools from the Manifest dynamically.\n\n### 2. Self-Testing (Snapshot System)\nTests write themselves from real executions. Run a cascade, freeze the execution as a snapshot, and replay it instantly without LLM calls to validate behavior.\n\n### 3. Self-Optimizing (Passive Optimization)\nPrompts improve automatically from usage data. The system tracks which prompts lead to successful outcomes and can suggest or apply optimizations.\n\n### 4. Self-Healing (Auto-Fix)\nFailed cells debug and repair themselves with LLM assistance. When a deterministic cell fails, an LLM can analyze the error and suggest fixes.\n\n### 5. Self-Building (Calliope)\nWorkflows constructed through natural language conversation. Users describe what they want, and Calliope generates the cascade definition.\n\n## Core Architecture\n\n### Cascade DSL\n\nCascades are JSON/YAML files validated via Pydantic models. Each cascade has:\n- cascade_id: Unique identifier\n- description: What this cascade does\n- inputs_schema: Expected input parameters\n- cells: List of execution cells\n\n### Cell Configuration\n\nLLM Cells use 'instructions' for prompts:\n- name: Cell identifier\n- instructions: Jinja2-templated system prompt\n- skills: Tools to inject\n- handoffs: Next-cell targets\n- rules: max_turns, loop_until, etc.\n\nDeterministic Cells use 'tool' for direct invocation:\n- name: Cell identifier  \n- tool: Direct tool call (e.g., 'sql_data')\n- inputs: Jinja2-templated tool inputs\n\n## Tool System\n\nFour Types of Tools:\n1. Python Functions: Registered via register_tackle()\n2. Cascade Tools: YAML cascades with inputs_schema\n3. Gradio Tools (Harbor): HuggingFace Spaces as tools\n4. Memory Tools: RAG-searchable knowledge bases\n\nBuilt-in Tools include:\n- Core: linux_shell, run_code, set_state, spawn_cascade, map_cascade\n- Data: sql_data, python_data, js_data, clojure_data\n- Human: ask_human, ask_human_custom\n- Visualization: create_chart, take_screenshot\n- Voice: say (TTS), listen (STT)\n\n## Context Management\n\nTwo-Level System:\n1. Intra-cell: Per-turn context within a cell (sliding window, observation masking)\n2. Inter-cell: Selective context injection between cells (heuristic, semantic, LLM, hybrid strategies)\n\nKey Principle: Never drop information - compress what the LLM sees, not what we store.\n\n## Observability\n\nAll executions log to ClickHouse via unified_logs:\n- Session tracking\n- Cost tracking per request\n- Token usage\n- Execution graphs (Mermaid)\n- Full request/response capture",

  "task": "Extract the key architectural decisions and design principles from this documentation. Focus on what makes LARS unique compared to other agent frameworks."
}
