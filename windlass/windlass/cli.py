import argparse
import json
import os
import random
import shutil
import sys
from pathlib import Path
from windlass import run_cascade
from windlass.event_hooks import EventPublishingHooks


SPLASH_DIR = Path(__file__).resolve().parent.parent / "tui_images"


def main():
    _maybe_render_startup_splash()
    parser = argparse.ArgumentParser(
        description="Windlass - Declarative Agent Framework",
        formatter_class=argparse.RawDescriptionHelpFormatter
    )

    subparsers = parser.add_subparsers(dest='command', help='Commands')

    # Run command (default)
    run_parser = subparsers.add_parser('run', help='Run a cascade (default command)')
    run_parser.add_argument("config", help="Path to cascade JSON config")
    run_parser.add_argument("--input", help="Path to input JSON file or raw JSON string", default="{}")
    run_parser.add_argument("--session", help="Session ID", default=None)
    run_parser.add_argument("--model", help="Override model name (e.g., 'ollama/mistral', 'anthropic/claude-sonnet-4.5')", default=None)
    run_parser.add_argument("--base-url", help="Override provider base URL (e.g., 'http://localhost:11434/v1' for Ollama)", default=None)
    run_parser.add_argument("--api-key", help="Override API key", default=None)

    # Render command
    render_parser = subparsers.add_parser('render', help='Render an image in the current terminal')
    render_parser.add_argument("image", help="Path to image file to render (e.g., dashboard/frontend/public/windlass-spicy.png)")
    render_parser.add_argument("--width", type=int, default=None, help="Max terminal columns to use (defaults to terminal width)")
    render_parser.add_argument(
        "--mode",
        choices=["auto", "kitty", "iterm2", "ansi"],
        default="auto",
        help="Force render mode (default: auto-detect)"
    )

    # Render Mermaid command
    render_mermaid_parser = subparsers.add_parser(
        'render-mermaid',
        help='Render a Mermaid diagram (from file or inline text) in the terminal'
    )
    render_mermaid_parser.add_argument("mermaid", help="Path to .mmd file or inline Mermaid text")
    render_mermaid_parser.add_argument("--width", type=int, default=None, help="Max terminal columns (defaults to terminal width)")
    render_mermaid_parser.add_argument(
        "--mode",
        choices=["auto", "kitty", "iterm2", "ansi"],
        default="auto",
        help="Force render mode (default: auto-detect)"
    )
    # Test command group
    test_parser = subparsers.add_parser('test', help='Cascade testing commands')
    test_subparsers = test_parser.add_subparsers(dest='test_command', help='Test subcommands')

    # test freeze
    freeze_parser = test_subparsers.add_parser(
        'freeze',
        help='Freeze a session execution as a test snapshot'
    )
    freeze_parser.add_argument('session_id', help='Session ID to freeze')
    freeze_parser.add_argument('--name', required=True, help='Name for the test snapshot')
    freeze_parser.add_argument('--description', default='', help='Description of what this tests')

    # test validate (alias: replay for backward compat)
    validate_parser = test_subparsers.add_parser(
        'validate',
        help='Validate a test snapshot',
        aliases=['replay']
    )
    validate_parser.add_argument('snapshot_name', help='Name of snapshot to validate')
    validate_parser.add_argument('--verbose', '-v', action='store_true', help='Verbose output')

    # test run
    run_tests_parser = test_subparsers.add_parser(
        'run',
        help='Run all test snapshots'
    )
    run_tests_parser.add_argument('--verbose', '-v', action='store_true', help='Verbose output')

    # test list
    list_parser = test_subparsers.add_parser(
        'list',
        help='List all test snapshots'
    )

    # Check command
    check_parser = subparsers.add_parser('check', help='Check optional dependencies (Rabbitize, Docker, etc.)')
    check_parser.add_argument('--feature', choices=['rabbitize', 'docker', 'all'], default='all',
                             help='Check specific feature or all (default: all)')

    # Analyze command
    analyze_parser = subparsers.add_parser('analyze', help='Analyze cascades and suggest improvements')
    analyze_parser.add_argument('cascade', help='Path to cascade JSON file')
    analyze_parser.add_argument('--phase', help='Specific phase to analyze (default: all phases)', default=None)
    analyze_parser.add_argument('--min-runs', type=int, default=10, help='Minimum runs needed for analysis')
    analyze_parser.add_argument('--apply', action='store_true', help='Automatically apply suggestions')
    analyze_parser.add_argument('--output', help='Save suggestions to file', default=None)

    # Data management command group
    data_parser = subparsers.add_parser('data', help='Data management commands')
    data_subparsers = data_parser.add_subparsers(dest='data_command', help='Data subcommands')

    # data compact (deprecated)
    compact_parser = data_subparsers.add_parser(
        'compact',
        help='DEPRECATED - ClickHouse handles compaction automatically'
    )
    compact_parser.add_argument(
        '--path',
        default=None,
        help='Directory to compact (default: $WINDLASS_DATA_DIR)'
    )
    compact_parser.add_argument(
        '--max-size',
        type=int,
        default=500,
        help='Maximum file size in MB (default: 500)'
    )
    compact_parser.add_argument(
        '--dry-run',
        action='store_true',
        help='Show what would be done without making changes'
    )
    compact_parser.add_argument(
        '--keep-originals',
        action='store_true',
        help='Keep original files after compaction (default: delete)'
    )
    compact_parser.add_argument(
        '--recursive',
        action='store_true',
        help='Also compact subdirectories (e.g., data/evals)'
    )

    # Database management command group
    db_parser = subparsers.add_parser('db', help='ClickHouse database management')
    db_subparsers = db_parser.add_subparsers(dest='db_command', help='Database subcommands')

    # db status
    db_status_parser = db_subparsers.add_parser(
        'status',
        help='Show ClickHouse database status and statistics'
    )

    # db init (ensure schema exists)
    db_init_parser = db_subparsers.add_parser(
        'init',
        help='Initialize ClickHouse schema (create tables if needed)'
    )

    # SQL query command
    sql_parser = subparsers.add_parser('sql', help='Query ClickHouse with SQL (supports magic table names)')
    sql_parser.add_argument('query', help='SQL query (use all_data, all_evals as table names)')
    sql_parser.add_argument('--format', choices=['table', 'json', 'csv'], default='table', help='Output format')
    sql_parser.add_argument('--limit', type=int, default=None, help='Limit number of rows displayed')

    # Embedding command group
    embed_parser = subparsers.add_parser('embed', help='Embedding system management')
    embed_subparsers = embed_parser.add_subparsers(dest='embed_command', help='Embedding subcommands')

    # embed status
    embed_status_parser = embed_subparsers.add_parser(
        'status',
        help='Show embedding worker status and statistics'
    )

    # embed run - manually run embedding on recent messages
    embed_run_parser = embed_subparsers.add_parser(
        'run',
        help='Run embedding on un-embedded messages'
    )
    embed_run_parser.add_argument('--batch-size', type=int, default=50, help='Number of messages to embed (default: 50)')
    embed_run_parser.add_argument('--dry-run', action='store_true', help='Show what would be embedded without making API calls')

    # embed costs
    embed_costs_parser = embed_subparsers.add_parser(
        'costs',
        help='Show embedding API costs'
    )

    # Hot or Not command group
    hotornot_parser = subparsers.add_parser('hotornot', help='Human evaluation system', aliases=['hon'])
    hotornot_subparsers = hotornot_parser.add_subparsers(dest='hotornot_command', help='Hot or Not subcommands')

    # hotornot rate - Interactive rating mode
    rate_parser = hotornot_subparsers.add_parser(
        'rate',
        help='Start interactive rating session (WASD controls)'
    )
    rate_parser.add_argument('--cascade', help='Filter by cascade file', default=None)
    rate_parser.add_argument('--limit', type=int, default=20, help='Number of items to rate')

    # hotornot stats - Show evaluation statistics
    stats_parser = hotornot_subparsers.add_parser(
        'stats',
        help='Show evaluation statistics'
    )

    # hotornot list - List unevaluated soundings
    list_uneval_parser = hotornot_subparsers.add_parser(
        'list',
        help='List unevaluated sounding outputs'
    )
    list_uneval_parser.add_argument('--limit', type=int, default=20, help='Max items to show')

    # hotornot quick - Quick binary rating of a specific session
    quick_parser = hotornot_subparsers.add_parser(
        'quick',
        help='Quick rate a specific session'
    )
    quick_parser.add_argument('session_id', help='Session ID to rate')
    quick_parser.add_argument('rating', choices=['good', 'bad', 'g', 'b', '+', '-'], help='Rating (good/bad)')
    quick_parser.add_argument('--phase', help='Specific phase', default=None)
    quick_parser.add_argument('--notes', help='Optional notes', default='')

    # Harbor (HuggingFace Spaces) command group
    harbor_parser = subparsers.add_parser('harbor', help='HuggingFace Spaces discovery and management')
    harbor_subparsers = harbor_parser.add_subparsers(dest='harbor_command', help='Harbor subcommands')

    # harbor list - List user's HF Spaces
    harbor_list_parser = harbor_subparsers.add_parser(
        'list',
        help='List your HuggingFace Spaces'
    )
    harbor_list_parser.add_argument('--author', help='Filter by author (default: current user)', default=None)
    harbor_list_parser.add_argument('--all', action='store_true', help='Include sleeping/paused spaces')

    # harbor introspect - Introspect a Space's API
    harbor_introspect_parser = harbor_subparsers.add_parser(
        'introspect',
        help='Introspect a Space to see its API endpoints and parameters'
    )
    harbor_introspect_parser.add_argument('space', help='HF Space ID (e.g., user/space-name)')

    # harbor export - Export a Space as a .tool.json
    harbor_export_parser = harbor_subparsers.add_parser(
        'export',
        help='Export a Space as a .tool.json definition'
    )
    harbor_export_parser.add_argument('space', help='HF Space ID (e.g., user/space-name)')
    harbor_export_parser.add_argument('--endpoint', help='Specific endpoint (default: first)', default=None)
    harbor_export_parser.add_argument('--tool-id', help='Custom tool ID', default=None)
    harbor_export_parser.add_argument('-o', '--output', help='Output file path', default=None)

    # harbor manifest - Show discovered Spaces as tools
    harbor_manifest_parser = harbor_subparsers.add_parser(
        'manifest',
        help='Show auto-discovered Spaces as tools'
    )

    # harbor wake - Wake a sleeping Space
    harbor_wake_parser = harbor_subparsers.add_parser(
        'wake',
        help='Wake up a sleeping HF Space'
    )
    harbor_wake_parser.add_argument('space', help='HF Space ID to wake')

    # harbor pause - Pause a running Space
    harbor_pause_parser = harbor_subparsers.add_parser(
        'pause',
        help='Pause a running HF Space (stops billing)'
    )
    harbor_pause_parser.add_argument('space', help='HF Space ID to pause')

    # harbor status - Show summary of all spaces with costs
    harbor_status_parser = harbor_subparsers.add_parser(
        'status',
        help='Show summary of all your HF Spaces with cost estimates'
    )

    # Triggers command group
    triggers_parser = subparsers.add_parser('triggers', help='Cascade trigger management and scheduling')
    triggers_subparsers = triggers_parser.add_subparsers(dest='triggers_command', help='Triggers subcommands')

    # triggers list - List triggers in a cascade
    triggers_list_parser = triggers_subparsers.add_parser(
        'list',
        help='List triggers defined in a cascade'
    )
    triggers_list_parser.add_argument('cascade', help='Path to cascade JSON file')

    # triggers export - Export triggers to external scheduler format
    triggers_export_parser = triggers_subparsers.add_parser(
        'export',
        help='Export triggers to external scheduler format (cron, systemd, kubernetes, airflow)'
    )
    triggers_export_parser.add_argument('cascade', help='Path to cascade JSON file')
    triggers_export_parser.add_argument(
        '--format', '-f',
        choices=['cron', 'systemd', 'kubernetes', 'airflow'],
        default='cron',
        help='Output format (default: cron)'
    )
    triggers_export_parser.add_argument('--output', '-o', help='Output file path (default: stdout)')
    triggers_export_parser.add_argument('--namespace', default='default', help='Kubernetes namespace (for k8s format)')
    triggers_export_parser.add_argument('--image', default='windlass:latest', help='Docker image (for k8s format)')
    triggers_export_parser.add_argument('--user', help='User to run as (for systemd format)')

    # triggers check - Check if a sensor trigger condition is met
    triggers_check_parser = triggers_subparsers.add_parser(
        'check',
        help='Check if a sensor trigger condition is met (exit 0 if ready, 1 if not)'
    )
    triggers_check_parser.add_argument('cascade', help='Path to cascade JSON file')
    triggers_check_parser.add_argument('trigger_name', help='Name of the sensor trigger to check')

    # Signals command group - cross-cascade communication
    signals_parser = subparsers.add_parser('signals', help='Signal management for cross-cascade communication')
    signals_subparsers = signals_parser.add_subparsers(dest='signals_command', help='Signals subcommands')

    # signals list - List waiting signals
    signals_list_parser = signals_subparsers.add_parser(
        'list',
        help='List signals currently waiting'
    )
    signals_list_parser.add_argument('--cascade', help='Filter by cascade ID')
    signals_list_parser.add_argument('--name', help='Filter by signal name')
    signals_list_parser.add_argument('--all', action='store_true', help='Show all signals (not just waiting)')

    # signals fire - Fire a signal
    signals_fire_parser = signals_subparsers.add_parser(
        'fire',
        help='Fire a signal to wake up waiting cascades'
    )
    signals_fire_parser.add_argument('signal_name', help='Name of the signal to fire')
    signals_fire_parser.add_argument('--payload', default='{}', help='JSON payload to pass to waiting cascades')
    signals_fire_parser.add_argument('--session', help='Only fire for a specific session ID')
    signals_fire_parser.add_argument('--source', default='cli', help='Source identifier (default: cli)')

    # signals status - Check signal status
    signals_status_parser = signals_subparsers.add_parser(
        'status',
        help='Check status of a specific signal'
    )
    signals_status_parser.add_argument('signal_id', help='Signal ID to check')

    # signals cancel - Cancel a waiting signal
    signals_cancel_parser = signals_subparsers.add_parser(
        'cancel',
        help='Cancel a waiting signal'
    )
    signals_cancel_parser.add_argument('signal_id', help='Signal ID to cancel')
    signals_cancel_parser.add_argument('--reason', help='Cancellation reason')

    # Sessions command group - durable execution coordination
    sessions_parser = subparsers.add_parser('sessions', help='Session management for durable execution')
    sessions_subparsers = sessions_parser.add_subparsers(dest='sessions_command', help='Sessions subcommands')

    # sessions list - List sessions
    sessions_list_parser = sessions_subparsers.add_parser(
        'list',
        help='List cascade sessions'
    )
    sessions_list_parser.add_argument('--status', choices=['running', 'blocked', 'completed', 'error', 'cancelled', 'orphaned', 'all'], default='all',
                                      help='Filter by status (default: all)')
    sessions_list_parser.add_argument('--cascade', help='Filter by cascade ID')
    sessions_list_parser.add_argument('--limit', type=int, default=50, help='Maximum sessions to show (default: 50)')

    # sessions show - Show session details
    sessions_show_parser = sessions_subparsers.add_parser(
        'show',
        help='Show details for a specific session'
    )
    sessions_show_parser.add_argument('session_id', help='Session ID to show')

    # sessions cancel - Request cancellation
    sessions_cancel_parser = sessions_subparsers.add_parser(
        'cancel',
        help='Request cancellation of a running session'
    )
    sessions_cancel_parser.add_argument('session_id', help='Session ID to cancel')
    sessions_cancel_parser.add_argument('--reason', help='Cancellation reason')

    # sessions cleanup - Clean up zombie sessions
    sessions_cleanup_parser = sessions_subparsers.add_parser(
        'cleanup',
        help='Mark zombie sessions (expired heartbeat) as orphaned'
    )
    sessions_cleanup_parser.add_argument('--dry-run', action='store_true', help='Show zombies without marking them')
    sessions_cleanup_parser.add_argument('--grace', type=int, default=30, help='Grace period in seconds beyond heartbeat lease (default: 30)')

    args = parser.parse_args()

    # Default to 'run' if no command specified and first arg looks like a file
    if args.command is None:
        if len(sys.argv) > 1 and (sys.argv[1].endswith('.json') or sys.argv[1].endswith('.yaml')):
            # Legacy mode: windlass config.json --input {...}
            args.command = 'run'
            args.config = sys.argv[1]

            # Parse remaining args for run command
            run_parser_standalone = argparse.ArgumentParser()
            run_parser_standalone.add_argument("config")
            run_parser_standalone.add_argument("--input", default="{}")
            run_parser_standalone.add_argument("--session", default=None)
            run_parser_standalone.add_argument("--model", default=None)
            run_parser_standalone.add_argument("--base-url", default=None)
            run_parser_standalone.add_argument("--api-key", default=None)
            standalone_args = run_parser_standalone.parse_args(sys.argv[1:])

            args.input = standalone_args.input
            args.session = standalone_args.session
            args.model = standalone_args.model
            args.base_url = standalone_args.base_url
            args.api_key = standalone_args.api_key
        else:
            parser.print_help()
            sys.exit(1)

    # Execute commands
    if args.command == 'run':
        cmd_run(args)
    elif args.command == 'render':
        cmd_render(args)
    elif args.command == 'render-mermaid':
        cmd_render_mermaid(args)
    elif args.command == 'check':
        cmd_check(args)
    elif args.command == 'test':
        if args.test_command == 'freeze':
            cmd_test_freeze(args)
        elif args.test_command in ['validate', 'replay']:
            cmd_test_validate(args)
        elif args.test_command == 'run':
            cmd_test_run(args)
        elif args.test_command == 'list':
            cmd_test_list(args)
        else:
            test_parser.print_help()
            sys.exit(1)
    elif args.command == 'analyze':
        cmd_analyze(args)
    elif args.command == 'data':
        if args.data_command == 'compact':
            cmd_data_compact(args)
        else:
            data_parser.print_help()
            sys.exit(1)
    elif args.command == 'db':
        if args.db_command == 'status':
            cmd_db_status(args)
        elif args.db_command == 'init':
            cmd_db_init(args)
        else:
            db_parser.print_help()
            sys.exit(1)
    elif args.command == 'sql':
        cmd_sql(args)
    elif args.command == 'embed':
        if args.embed_command == 'status':
            cmd_embed_status(args)
        elif args.embed_command == 'run':
            cmd_embed_run(args)
        elif args.embed_command == 'costs':
            cmd_embed_costs(args)
        else:
            embed_parser.print_help()
            sys.exit(1)
    elif args.command in ['hotornot', 'hon']:
        if args.hotornot_command == 'rate':
            cmd_hotornot_rate(args)
        elif args.hotornot_command == 'stats':
            cmd_hotornot_stats(args)
        elif args.hotornot_command == 'list':
            cmd_hotornot_list(args)
        elif args.hotornot_command == 'quick':
            cmd_hotornot_quick(args)
        else:
            hotornot_parser.print_help()
            sys.exit(1)
    elif args.command == 'harbor':
        if args.harbor_command == 'list':
            cmd_harbor_list(args)
        elif args.harbor_command == 'introspect':
            cmd_harbor_introspect(args)
        elif args.harbor_command == 'export':
            cmd_harbor_export(args)
        elif args.harbor_command == 'manifest':
            cmd_harbor_manifest(args)
        elif args.harbor_command == 'wake':
            cmd_harbor_wake(args)
        elif args.harbor_command == 'pause':
            cmd_harbor_pause(args)
        elif args.harbor_command == 'status':
            cmd_harbor_status(args)
        else:
            harbor_parser.print_help()
            sys.exit(1)
    elif args.command == 'triggers':
        if args.triggers_command == 'list':
            cmd_triggers_list(args)
        elif args.triggers_command == 'export':
            cmd_triggers_export(args)
        elif args.triggers_command == 'check':
            cmd_triggers_check(args)
        else:
            triggers_parser.print_help()
            sys.exit(1)
    elif args.command == 'signals':
        if args.signals_command == 'list':
            cmd_signals_list(args)
        elif args.signals_command == 'fire':
            cmd_signals_fire(args)
        elif args.signals_command == 'status':
            cmd_signals_status(args)
        elif args.signals_command == 'cancel':
            cmd_signals_cancel(args)
        else:
            signals_parser.print_help()
            sys.exit(1)
    elif args.command == 'sessions':
        if args.sessions_command == 'list':
            cmd_sessions_list(args)
        elif args.sessions_command == 'show':
            cmd_sessions_show(args)
        elif args.sessions_command == 'cancel':
            cmd_sessions_cancel(args)
        elif args.sessions_command == 'cleanup':
            cmd_sessions_cleanup(args)
        else:
            sessions_parser.print_help()
            sys.exit(1)
    else:
        parser.print_help()
        sys.exit(1)


def cmd_render(args):
    """Render an image in the terminal using the best supported protocol."""
    try:
        from windlass.terminal_image import render_image_in_terminal

        force_mode = None if args.mode == "auto" else args.mode
        render_image_in_terminal(args.image, max_width=args.width, force_mode=force_mode)
    except FileNotFoundError as e:
        print(f"âœ— {e}", file=sys.stderr)
        sys.exit(1)
    except ImportError as e:
        print(f"âœ— {e}", file=sys.stderr)
        sys.exit(1)
    except Exception as e:
        print(f"âœ— Failed to render image: {e}", file=sys.stderr)
        sys.exit(1)


def cmd_render_mermaid(args):
    """Render a Mermaid diagram from file or inline text in the terminal."""
    try:
        from windlass.mermaid_terminal import render_mermaid_in_terminal, MermaidRenderError

        force_mode = None if args.mode == "auto" else args.mode
        is_path = os.path.exists(args.mermaid)
        render_mermaid_in_terminal(args.mermaid, max_width=args.width, force_mode=force_mode, is_path=is_path)
    except MermaidRenderError as e:
        print(f"âœ— {e}", file=sys.stderr)
        sys.exit(1)
    except FileNotFoundError as e:
        print(f"âœ— {e}", file=sys.stderr)
        sys.exit(1)
    except ImportError as e:
        print(f"âœ— {e}", file=sys.stderr)
        sys.exit(1)
    except Exception as e:
        print(f"âœ— Failed to render Mermaid diagram: {e}", file=sys.stderr)
        sys.exit(1)


def _maybe_render_startup_splash():
    """Render a random TUI splash image on startup if interactive."""
    if os.environ.get("WINDLASS_NO_SPLASH"):
        return
    if not sys.stdout.isatty():
        return

    try:
        from windlass.terminal_image import render_image_in_terminal
    except Exception:
        return

    if not SPLASH_DIR.exists():
        return

    images = [p for p in SPLASH_DIR.iterdir() if p.is_file() and p.suffix.lower() in {".png", ".jpg", ".jpeg", ".webp"}]
    if not images:
        return

    try:
        cols = shutil.get_terminal_size((80, 24)).columns
    except OSError:
        cols = 80
    max_width = max(20, min(cols, 80))

    image_path = random.choice(images)
    try:
        render_image_in_terminal(str(image_path), max_width=max_width)
        print()  # spacing after splash
    except Exception:
        # Splash is best-effort; ignore failures.
        pass


def cmd_run(args):
    """Run a cascade."""
    # Ensure declarative tools are discovered and registered
    try:
        from .tool_definitions import discover_and_register_declarative_tools
        discover_and_register_declarative_tools()
    except Exception:
        pass  # Non-fatal if tool discovery fails

    # Generate session ID if not provided - use woodland naming
    if args.session is None:
        from windlass.session_naming import auto_generate_session_id
        session_id = auto_generate_session_id()
    else:
        session_id = args.session

    # Parse input
    if os.path.exists(args.input):
        with open(args.input, 'r') as f:
            input_data = json.load(f)
    else:
        try:
            input_data = json.loads(args.input)
        except json.JSONDecodeError:
            input_data = {"raw": args.input}

    # Build overrides dict from CLI flags
    overrides = {}
    if hasattr(args, 'model') and args.model:
        overrides['model'] = args.model
        print(f"ðŸ”§ Model override: {args.model}")
    if hasattr(args, 'base_url') and args.base_url:
        overrides['base_url'] = args.base_url
        print(f"ðŸ”§ Base URL override: {args.base_url}")
    if hasattr(args, 'api_key') and args.api_key:
        overrides['api_key'] = args.api_key
        print(f"ðŸ”§ API key override: ***")

    print(f"Running cascade: {args.config}")
    print(f"Session ID: {session_id}")
    print()

    # Enable event hooks for real-time updates
    hooks = EventPublishingHooks()

    result = run_cascade(args.config, input_data, session_id, overrides=overrides, hooks=hooks)

    print()
    print("="*60)
    print("RESULT")
    print("="*60)
    print(json.dumps(result, indent=2))


def cmd_test_freeze(args):
    """Freeze a session as a test snapshot."""
    from windlass.testing import SnapshotCapture

    try:
        capturer = SnapshotCapture()
        snapshot_file = capturer.freeze(
            args.session_id,
            args.name,
            args.description
        )

        print()
        print("âœ“ Test snapshot created successfully!")
        print()
        print("Next steps:")
        print(f"  â€¢ Replay: windlass test replay {args.name}")
        print(f"  â€¢ Run all: windlass test run")
        print(f"  â€¢ Pytest: pytest tests/test_snapshots.py")

    except Exception as e:
        print(f"âœ— Failed to freeze snapshot: {e}", file=sys.stderr)
        sys.exit(1)


def cmd_test_validate(args):
    """Validate a test snapshot."""
    from windlass.testing import SnapshotValidator

    try:
        validator = SnapshotValidator()
        result = validator.validate(args.snapshot_name, verbose=args.verbose)

        if result["passed"]:
            print(f"âœ“ {result['snapshot_name']} PASSED")
            if not args.verbose:
                print(f"  {len(result['checks'])} checks passed")
            sys.exit(0)
        else:
            print(f"âœ— {result['snapshot_name']} FAILED")
            print()
            for failure in result["failures"]:
                print(f"  Failure: {failure.get('message', 'Unknown')}")
                if 'expected' in failure:
                    print(f"    Expected: {failure['expected']}")
                if 'actual' in failure:
                    print(f"    Actual: {failure['actual']}")
            sys.exit(1)

    except Exception as e:
        print(f"âœ— Error validating snapshot: {e}", file=sys.stderr)
        sys.exit(1)


def cmd_test_run(args):
    """Run all test snapshots."""
    from windlass.testing import SnapshotValidator

    validator = SnapshotValidator()
    results = validator.validate_all(verbose=args.verbose)

    if results["total"] == 0:
        print("No test snapshots found.")
        print()
        print("Create one with: windlass test freeze <session_id> --name <name>")
        sys.exit(0)

    print()
    print("="*60)
    print(f"Running {results['total']} test snapshot(s)")
    print("="*60)
    print()

    for snapshot_result in results["snapshots"]:
        if snapshot_result["passed"]:
            print(f"  âœ“ {snapshot_result['snapshot_name']}")
        else:
            print(f"  âœ— {snapshot_result['snapshot_name']}")
            for failure in snapshot_result["failures"]:
                print(f"      {failure.get('message', 'Unknown failure')}")

    print()
    print("="*60)
    print(f"Results: {results['passed']}/{results['total']} passed")
    print("="*60)

    if results["failed"] > 0:
        sys.exit(1)


def cmd_test_list(args):
    """List all test snapshots."""
    from pathlib import Path
    import json

    snapshot_dir = Path("tests/cascade_snapshots")

    if not snapshot_dir.exists():
        print("No test snapshots found.")
        print()
        print("Create one with: windlass test freeze <session_id> --name <name>")
        return

    snapshots = list(snapshot_dir.glob("*.json"))

    if not snapshots:
        print("No test snapshots found.")
        return

    print()
    print(f"Found {len(snapshots)} test snapshot(s):")
    print()

    for snapshot_file in sorted(snapshots):
        with open(snapshot_file) as f:
            snapshot = json.load(f)

        print(f"  â€¢ {snapshot['snapshot_name']}")
        if snapshot.get('description'):
            print(f"      {snapshot['description']}")
        print(f"      Cascade: {snapshot.get('cascade_file', 'unknown')}")
        print(f"      Phases: {', '.join(p['name'] for p in snapshot['execution']['phases'])}")
        print(f"      Captured: {snapshot['captured_at'][:10]}")
        print()


def cmd_analyze(args):
    """Analyze cascade and suggest prompt improvements."""
    from windlass.analyzer import analyze_and_suggest, PromptSuggestionManager

    try:
        # Run analysis
        analysis = analyze_and_suggest(
            args.cascade,
            phase_name=args.phase,
            min_runs=args.min_runs
        )

        if not analysis.get("suggestions"):
            print("\nNo suggestions available.")
            print("This could mean:")
            print("  â€¢ Not enough runs yet (need at least", args.min_runs, ")")
            print("  â€¢ No clear winner (< 60% win rate)")
            print("  â€¢ No soundings configured in cascade")
            sys.exit(0)

        # Display suggestions
        print()
        print("="*70)
        print(f"PROMPT IMPROVEMENT SUGGESTIONS")
        print("="*70)
        print()

        for i, suggestion in enumerate(analysis["suggestions"], 1):
            print(f"{i}. Phase: {suggestion['phase']}")
            print()
            print(f"   Current:")
            print(f"   \"{suggestion['current_instruction'][:100]}...\"")
            print()
            print(f"   Suggested:")
            print(f"   \"{suggestion['suggested_instruction'][:100]}...\"")
            print()
            print(f"   Impact:")
            print(f"   â€¢ Cost: {suggestion['impact']['cost_improvement']} improvement")
            print(f"   â€¢ Confidence: {suggestion['impact']['confidence']}")
            print(f"   â€¢ Based on: {suggestion['impact']['based_on_runs']} winning runs")
            print()
            print(f"   Rationale:")
            for line in suggestion['rationale'].split('\n'):
                print(f"   {line}")
            print()
            print("-"*70)
            print()

        # Save suggestions
        if args.output:
            manager = PromptSuggestionManager()
            filepath = manager.suggestions_dir / args.output
            with open(filepath, 'w') as f:
                json.dump(analysis, f, indent=2)
            print(f"âœ“ Suggestions saved to: {filepath}")
        else:
            manager = PromptSuggestionManager()
            filepath = manager.save_suggestions(analysis)

        # Apply if requested
        if args.apply:
            print()
            print("Applying suggestions...")
            manager = PromptSuggestionManager()

            for suggestion in analysis["suggestions"]:
                success = manager.apply_suggestion(
                    args.cascade,
                    suggestion["phase"],
                    suggestion["suggested_instruction"],
                    auto_commit=True
                )

                if success:
                    print(f"âœ“ Applied suggestion for phase: {suggestion['phase']}")
                else:
                    print(f"âœ— Failed to apply suggestion for phase: {suggestion['phase']}")

            print()
            print("âœ“ All suggestions applied!")
            print()
            print("Review changes:")
            print(f"  git diff {args.cascade}")

        else:
            print()
            print("To apply suggestions:")
            print(f"  windlass analyze {args.cascade} --apply")
            print()
            print("Or apply manually and commit to git")

    except Exception as e:
        print(f"âœ— Error analyzing cascade: {e}", file=sys.stderr)
        import traceback
        traceback.print_exc()
        sys.exit(1)


# ========== SQL QUERY COMMAND ==========

def cmd_sql(args):
    """Execute a SQL query against ClickHouse with magic table name translation."""
    import re
    from windlass.config import get_config, get_clickhouse_url
    from windlass.db_adapter import get_db_adapter
    from rich.console import Console
    from rich.table import Table

    # Short-circuit for discovery commands
    if args.query.lower() in ("chart", "discover", "scan"):
        from windlass.sql_tools.discovery import discover_all_schemas
        discover_all_schemas()
        return

    config = get_config()
    db = get_db_adapter()

    # Magic table name mappings - now map to actual ClickHouse tables
    table_mappings = {
        'all_data': 'unified_logs',
        'all_evals': 'evaluations',
        'all_prefs': 'training_preferences',
        'rag': 'rag_chunks',
        'rag_docs': 'rag_manifests',
        'checkpoints': 'checkpoints',
    }

    # Preprocess query to replace magic table names
    query = args.query

    # Replace table names (case-insensitive)
    for magic_name, replacement in table_mappings.items():
        pattern = r'\b' + magic_name + r'\b'
        query = re.sub(pattern, replacement, query, flags=re.IGNORECASE)

    try:
        # Execute query
        df = db.query(query, output_format="dataframe")

        # Apply limit if specified
        if args.limit and len(df) > args.limit:
            df = df.head(args.limit)
            print(f"(Showing {args.limit} of {len(df)} rows)")
            print()

        # Output in requested format
        if df.empty:
            print("No results found.")
            return

        if args.format == 'table':
            # Pretty table output using Rich
            console = Console()
            table = Table(show_header=True, header_style="bold magenta")

            # Add columns
            for col in df.columns:
                table.add_column(str(col))

            # Add rows (limit to reasonable display size)
            for _, row in df.iterrows():
                table.add_row(*[str(val) for val in row])

            print()
            console.print(table)
            print()
            print(f"({len(df)} rows)")
        elif args.format == 'json':
            print(df.to_json(orient='records', indent=2))
        elif args.format == 'csv':
            print(df.to_csv(index=False))

    except Exception as e:
        print(f"âœ— Query failed: {e}", file=sys.stderr)
        print()
        print(f"ClickHouse: {get_clickhouse_url()}")
        print()
        print("Available tables (magic names â†’ actual):")
        for magic, actual in table_mappings.items():
            print(f"  â€¢ {magic} â†’ {actual}")
        print()
        print("Example queries:")
        print("  windlass sql \"SELECT * FROM all_data LIMIT 10\"")
        print("  windlass sql \"SELECT session_id, SUM(cost) FROM unified_logs GROUP BY session_id\"")
        print("  windlass sql \"SELECT * FROM rag WHERE rag_id = 'abc123' LIMIT 5\"")
        sys.exit(1)


# ========== DATA MANAGEMENT COMMANDS ==========

def cmd_data_compact(args):
    """
    DEPRECATED: Compact Parquet files.

    This command is no longer needed since Windlass now stores data directly
    in ClickHouse. Data management is handled automatically by ClickHouse.

    Use 'windlass db status' to check database health.
    """
    from windlass.config import get_clickhouse_url

    print()
    print("="*60)
    print("DEPRECATED COMMAND")
    print("="*60)
    print()
    print("The 'data compact' command is no longer needed.")
    print()
    print("Windlass now stores all data directly in ClickHouse:")
    print(f"  {get_clickhouse_url()}")
    print()
    print("ClickHouse handles data compaction automatically via:")
    print("  â€¢ MergeTree engine background merges")
    print("  â€¢ Partitioning by month (toYYYYMM)")
    print("  â€¢ TTL-based data expiration")
    print()
    print("To check database status:")
    print("  windlass db status")
    print()
    print("To optimize tables manually (if needed):")
    print("  windlass sql \"OPTIMIZE TABLE unified_logs FINAL\"")
    print()


def cmd_db_status(args):
    """Show ClickHouse database status and statistics."""
    from windlass.config import get_clickhouse_url
    from windlass.db_adapter import get_db
    from rich.console import Console
    from rich.table import Table

    console = Console()

    print()
    print("="*60)
    print("CLICKHOUSE DATABASE STATUS")
    print("="*60)
    print()
    print(f"Connection: {get_clickhouse_url()}")
    print()

    try:
        db = get_db()

        # Get table statistics
        tables_info = db.query("""
            SELECT
                name as table_name,
                formatReadableSize(total_bytes) as size,
                formatReadableQuantity(total_rows) as rows,
                partition_count
            FROM (
                SELECT
                    table as name,
                    sum(bytes) as total_bytes,
                    sum(rows) as total_rows,
                    count() as partition_count
                FROM system.parts
                WHERE database = currentDatabase()
                  AND active
                GROUP BY table
            )
            ORDER BY total_bytes DESC
        """)

        if tables_info:
            table = Table(title="Table Statistics", show_header=True, header_style="bold cyan")
            table.add_column("Table")
            table.add_column("Size", justify="right")
            table.add_column("Rows", justify="right")
            table.add_column("Partitions", justify="right")

            for row in tables_info:
                table.add_row(
                    row['table_name'],
                    row['size'],
                    row['rows'],
                    str(row['partition_count'])
                )

            console.print(table)
        else:
            print("No tables with data found.")

        print()
        print("âœ“ Database connection OK")
        print()

    except Exception as e:
        print(f"âœ— Database connection failed: {e}")
        print()
        print("Check that ClickHouse is running and accessible.")
        sys.exit(1)


def cmd_db_init(args):
    """Initialize ClickHouse schema (create tables if needed)."""
    from windlass.config import get_clickhouse_url
    from windlass.db_adapter import get_db
    from windlass.schema import ensure_schema

    print()
    print("="*60)
    print("CLICKHOUSE SCHEMA INITIALIZATION")
    print("="*60)
    print()
    print(f"Connection: {get_clickhouse_url()}")
    print()

    try:
        db = get_db()
        print("Creating/verifying tables...")
        print()

        ensure_schema(db)

        print()
        print("âœ“ Schema initialization complete!")
        print()
        print("Run 'windlass db status' to view table statistics.")
        print()

    except Exception as e:
        print(f"âœ— Schema initialization failed: {e}")
        print()
        import traceback
        traceback.print_exc()
        sys.exit(1)


# ========== EMBEDDING COMMANDS ==========

def cmd_embed_status(args):
    """Show embedding worker status and statistics."""
    from windlass.db_adapter import get_db_adapter
    from windlass.config import get_config
    from windlass.embedding_worker import get_embedding_worker, get_embedding_costs

    config = get_config()
    db = get_db_adapter()

    print()
    print("="*60)
    print("EMBEDDING SYSTEM STATUS")
    print("="*60)
    print()

    # Configuration
    print(f"Embed Model: {config.default_embed_model}")
    print(f"Provider: {config.provider_base_url}")
    print()

    # Worker status
    worker = get_embedding_worker()
    stats = worker.get_stats()
    print("Background Worker:")
    print(f"  Enabled: {stats['enabled']}")
    print(f"  Running: {stats['running']}")
    print(f"  Processed: {stats['processed_count']}")
    print(f"  Errors: {stats['error_count']}")
    if stats['last_run']:
        print(f"  Last Run: {stats['last_run']}")
    print()

    # Database stats
    # Count embeddable rows: assistant/user roles OR sounding_attempt/evaluator node types
    try:
        result = db.query("""
            SELECT
                countIf(length(content_embedding) > 0) as embedded,
                countIf(
                    length(content_embedding) = 0
                    AND length(content_json) > 10
                    AND (role IN ('assistant', 'user') OR node_type IN ('sounding_attempt', 'evaluator', 'agent', 'follow_up'))
                    AND node_type NOT IN ('embedding', 'tool_call', 'tool_result', 'phase', 'cascade', 'system', 'link', 'soundings', 'validation', 'validation_start')
                ) as unembedded,
                COUNT(*) as total
            FROM unified_logs
        """, output_format='dict')

        if result:
            r = result[0]
            embedded = r.get('embedded', 0)
            unembedded = r.get('unembedded', 0)
            total = r.get('total', 0)

            print("Message Embeddings:")
            print(f"  Embedded: {embedded}")
            print(f"  Pending: {unembedded}")
            print(f"  Total Messages: {total}")
            if embedded + unembedded > 0:
                pct = (embedded / (embedded + unembedded)) * 100
                print(f"  Coverage: {pct:.1f}%")
            print()
    except Exception as e:
        print(f"  Error querying stats: {e}")
        print()

    # Embedding costs
    costs = get_embedding_costs()
    print("Embedding API Costs:")
    print(f"  Total Cost: ${costs['total_cost']:.6f}")
    print(f"  Total Tokens: {costs['total_tokens']}")
    print(f"  API Calls: {costs['call_count']}")
    print()

    print("To enable background embedding:")
    print("  export WINDLASS_ENABLE_EMBEDDINGS=true")
    print()
    print("To manually embed recent messages:")
    print("  windlass embed run --batch-size 100")
    print()


def cmd_embed_run(args):
    """Manually run embedding on un-embedded messages."""
    from windlass.db_adapter import get_db_adapter
    from windlass.config import get_config
    from windlass.agent import Agent
    from windlass.embedding_worker import EMBEDDING_SESSION_ID, EMBEDDING_CASCADE_ID, EMBEDDING_PHASE_NAME
    import uuid
    import json as json_lib

    config = get_config()
    db = get_db_adapter()
    batch_size = args.batch_size

    print()
    print("="*60)
    print("EMBEDDING RUN")
    print("="*60)
    print()
    print(f"Model: {config.default_embed_model}")
    print(f"Batch Size: {batch_size}")
    print(f"Dry Run: {args.dry_run}")
    print()

    # Query for un-embedded messages
    # Include: assistant/user roles AND sounding_attempt/evaluator node types
    # (sounding_attempt is where is_winner is set - critical for analysis!)
    query = f"""
        SELECT
            message_id,
            trace_id,
            role,
            content_json,
            session_id,
            phase_name,
            cascade_id
        FROM unified_logs
        WHERE length(content_embedding) = 0
          AND content_json IS NOT NULL
          AND length(content_json) > 10
          AND (
              role IN ('assistant', 'user')
              OR node_type IN ('sounding_attempt', 'evaluator', 'agent', 'follow_up')
          )
          AND node_type NOT IN ('embedding', 'tool_call', 'tool_result', 'phase', 'cascade', 'system', 'link', 'soundings', 'validation', 'validation_start')
        ORDER BY timestamp DESC
        LIMIT {batch_size}
    """

    try:
        rows = db.query(query, output_format='dict')
    except Exception as e:
        print(f"Error querying messages: {e}")
        sys.exit(1)

    if not rows:
        print("No un-embedded messages found.")
        print()
        return

    print(f"Found {len(rows)} messages to embed")
    print()

    if args.dry_run:
        print("DRY RUN - Would embed:")
        for i, row in enumerate(rows[:10]):
            content = row.get('content_json', '')[:50]
            print(f"  {i+1}. [{row['role']}] {row['trace_id'][:12]}... {content}...")
        if len(rows) > 10:
            print(f"  ... and {len(rows) - 10} more")
        print()
        return

    # Extract texts
    texts = []
    valid_rows = []
    for row in rows:
        content = row.get('content_json')
        if isinstance(content, str):
            try:
                parsed = json_lib.loads(content)
                if isinstance(parsed, str):
                    text = parsed
                elif isinstance(parsed, dict):
                    text = parsed.get('content', str(parsed))
                else:
                    text = str(parsed)
            except:
                text = content
        else:
            text = str(content)

        if len(text.strip()) < 10:
            continue

        # Truncate long content
        if len(text) > 8000:
            text = text[:8000] + "..."

        texts.append(text)
        valid_rows.append(row)

    if not texts:
        print("No valid text content to embed.")
        return

    print(f"Embedding {len(texts)} texts...")

    trace_id = f"embed_cli_{uuid.uuid4().hex[:12]}"

    try:
        result = Agent.embed(
            texts=texts,
            model=config.default_embed_model,
            session_id=EMBEDDING_SESSION_ID,
            trace_id=trace_id,
            cascade_id=EMBEDDING_CASCADE_ID,
            phase_name=EMBEDDING_PHASE_NAME,
        )
    except Exception as e:
        print(f"Embedding API error: {e}")
        sys.exit(1)

    vectors = result.get('embeddings', [])
    dim = result.get('dim', 0)
    model_used = result.get('model', config.default_embed_model)

    print(f"  Model: {model_used}")
    print(f"  Dimensions: {dim}")
    print(f"  Vectors: {len(vectors)}")
    print()

    # Update database
    print("Updating database...")
    updated = 0
    for row, vector in zip(valid_rows, vectors):
        try:
            db.update_row(
                table='unified_logs',
                updates={
                    'content_embedding': vector,
                    'embedding_model': model_used,
                    'embedding_dim': dim,
                },
                where=f"trace_id = '{row['trace_id']}'",
                sync=False
            )
            updated += 1
        except Exception as e:
            print(f"  Error updating {row['trace_id']}: {e}")

    print(f"  Updated {updated} rows")
    print()
    print("Done!")
    print()


def cmd_embed_costs(args):
    """Show embedding API costs."""
    from windlass.db_adapter import get_db_adapter
    from windlass.embedding_worker import EMBEDDING_CASCADE_ID
    from rich.console import Console
    from rich.table import Table

    db = get_db_adapter()
    console = Console()

    print()
    print("="*60)
    print("EMBEDDING API COSTS")
    print("="*60)
    print()

    # Overall costs
    try:
        result = db.query(f"""
            SELECT
                SUM(cost) as total_cost,
                SUM(tokens_in) as total_tokens,
                COUNT(*) as call_count,
                MIN(timestamp) as first_call,
                MAX(timestamp) as last_call
            FROM unified_logs
            WHERE cascade_id = '{EMBEDDING_CASCADE_ID}'
              AND node_type = 'embedding'
        """, output_format='dict')

        if result and result[0].get('call_count', 0) > 0:
            r = result[0]
            print(f"Total Cost: ${r['total_cost']:.6f}")
            print(f"Total Tokens: {r['total_tokens']}")
            print(f"API Calls: {r['call_count']}")
            print(f"First Call: {r['first_call']}")
            print(f"Last Call: {r['last_call']}")
            print()
        else:
            print("No embedding API calls recorded yet.")
            print()
            return

    except Exception as e:
        print(f"Error: {e}")
        return

    # Breakdown by day
    try:
        result = db.query(f"""
            SELECT
                toDate(timestamp) as day,
                SUM(cost) as cost,
                SUM(tokens_in) as tokens,
                COUNT(*) as calls
            FROM unified_logs
            WHERE cascade_id = '{EMBEDDING_CASCADE_ID}'
              AND node_type = 'embedding'
            GROUP BY day
            ORDER BY day DESC
            LIMIT 10
        """, output_format='dict')

        if result:
            print("Daily Breakdown (Last 10 Days):")
            table = Table(show_header=True, header_style="bold cyan")
            table.add_column("Date")
            table.add_column("Cost", justify="right")
            table.add_column("Tokens", justify="right")
            table.add_column("Calls", justify="right")

            for r in result:
                table.add_row(
                    str(r['day']),
                    f"${r['cost']:.6f}",
                    str(r['tokens']),
                    str(r['calls'])
                )

            console.print(table)
            print()

    except Exception as e:
        print(f"Error getting daily breakdown: {e}")
        print()


# ========== HOT OR NOT COMMANDS ==========

def cmd_hotornot_stats(args):
    """Show evaluation statistics."""
    from windlass.hotornot import get_evaluation_stats

    stats = get_evaluation_stats()

    print()
    print("="*50)
    print("HOT OR NOT - Evaluation Statistics")
    print("="*50)
    print()

    if stats.get("error"):
        print(f"Error: {stats['error']}")
        return

    if stats["total_evaluations"] == 0:
        print("No evaluations yet!")
        print()
        print("Start rating with:")
        print("  windlass hotornot rate")
        print()
        print("Or quick-rate a session:")
        print("  windlass hotornot quick <session_id> good")
        return

    print(f"Total evaluations: {stats['total_evaluations']}")
    print()
    print("Binary ratings:")
    print(f"  Good: {stats['binary_good']}")
    print(f"  Bad:  {stats['binary_bad']}")
    if stats['binary_good'] + stats['binary_bad'] > 0:
        good_rate = stats['binary_good'] / (stats['binary_good'] + stats['binary_bad']) * 100
        print(f"  Good rate: {good_rate:.1f}%")
    print()
    print("Preference evaluations:")
    print(f"  Total: {stats['preferences_total']}")
    print(f"  Agreed with system: {stats['preferences_agreed']}")
    print(f"  Agreement rate: {stats['agreement_rate']}%")
    print()
    print(f"Flagged for review: {stats['flags']}")
    print()


def cmd_hotornot_list(args):
    """List unevaluated soundings."""
    from windlass.hotornot import get_unevaluated_soundings

    df = get_unevaluated_soundings(limit=args.limit)

    if df.empty:
        print()
        print("No unevaluated soundings found!")
        print()
        print("Run some cascades with soundings first:")
        print("  windlass examples/soundings_flow.json --input '{}'")
        return

    print()
    print("="*60)
    print(f"Unevaluated Soundings (showing {len(df)})")
    print("="*60)
    print()

    # Group by session+phase
    grouped = df.groupby(['session_id', 'phase_name'])

    for (session_id, phase_name), group in grouped:
        winner_row = group[group['is_winner'] == True]
        winner_idx = winner_row['sounding_index'].values[0] if not winner_row.empty else '?'

        print(f"Session: {session_id[:30]}...")
        print(f"  Phase: {phase_name}")
        print(f"  Soundings: {len(group)} variants")
        print(f"  System winner: #{winner_idx}")
        print()

    print()
    print("Start rating with:")
    print("  windlass hotornot rate")
    print()


def cmd_hotornot_quick(args):
    """Quick-rate a specific session."""
    from windlass.hotornot import log_binary_eval, flush_evaluations

    is_good = args.rating in ['good', 'g', '+']

    eval_id = log_binary_eval(
        session_id=args.session_id,
        is_good=is_good,
        phase_name=args.phase,
        notes=args.notes
    )

    flush_evaluations()

    emoji = "" if is_good else ""
    rating_str = "GOOD" if is_good else "BAD"

    print()
    print(f"{emoji} Rated session {args.session_id[:20]}... as {rating_str}")
    if args.phase:
        print(f"   Phase: {args.phase}")
    if args.notes:
        print(f"   Notes: {args.notes}")
    print()


def cmd_hotornot_rate(args):
    """Interactive rating session with WASD controls."""
    from windlass.hotornot import (
        get_unevaluated_soundings, get_sounding_group,
        log_binary_eval, log_preference_eval, log_flag_eval,
        flush_evaluations
    )

    try:
        import readchar
    except ImportError:
        print("Interactive mode requires 'readchar' package.")
        print("Install with: pip install readchar")
        print()
        print("Or use quick mode:")
        print("  windlass hotornot quick <session_id> good")
        sys.exit(1)

    print()
    print("="*60)
    print("HOT OR NOT - Interactive Rating")
    print("="*60)
    print()
    print("Controls:")
    print("  A / Left Arrow  = BAD ()")
    print("  D / Right Arrow = GOOD ()")
    print("  S / Down Arrow  = SKIP")
    print("  W / Up Arrow    = FLAG for review")
    print("  Q               = Quit")
    print()
    print("Loading soundings to rate...")
    print()

    # Get items to rate
    df = get_unevaluated_soundings(limit=args.limit * 3)  # Get extra in case of grouping

    if df.empty:
        print("No soundings to rate!")
        print("Run cascades with soundings first.")
        return

    # Get unique session+phase combinations
    combos = df.groupby(['session_id', 'phase_name']).first().reset_index()[['session_id', 'phase_name']]

    rated_count = 0
    good_count = 0
    bad_count = 0
    skip_count = 0
    flag_count = 0
    streak = 0

    for idx, row in combos.iterrows():
        if rated_count >= args.limit:
            break

        session_id = row['session_id']
        phase_name = row['phase_name']

        # Get the sounding group
        group = get_sounding_group(session_id, phase_name)
        if not group or not group.get('soundings'):
            continue

        # Clear screen (simple version)
        print("\033[2J\033[H", end="")  # ANSI clear

        print("="*60)
        print(f"HOT OR NOT  |  {rated_count + 1}/{args.limit}  |  Streak: {streak}")
        print("="*60)
        print()
        print(f"Cascade: {group.get('cascade_id', 'unknown')}")
        print(f"Phase: {phase_name}")
        print(f"Session: {session_id[:40]}...")
        print()

        # Show system winner
        winner_idx = group.get('system_winner_index', 0)
        winner_sounding = None
        for s in group['soundings']:
            if s['index'] == winner_idx:
                winner_sounding = s
                break

        if winner_sounding:
            print("-"*60)
            print(f"System picked: Sounding #{winner_idx + 1}")
            if winner_sounding.get('mutation_applied'):
                print(f"Mutation: {winner_sounding['mutation_applied'][:60]}...")
            print("-"*60)
            print()

            content = winner_sounding.get('content', '')
            if isinstance(content, dict):
                content = json.dumps(content, indent=2)
            elif isinstance(content, list):
                content = json.dumps(content, indent=2)

            # Truncate for display
            if len(str(content)) > 800:
                content = str(content)[:800] + "\n... (truncated)"

            print(content)
            print()

        print("-"*60)
        print("[A] BAD    [D] GOOD    [S] Skip    [W] Flag    [Q] Quit")
        print("-"*60)

        # Get input
        try:
            key = readchar.readkey()
        except KeyboardInterrupt:
            break

        if key.lower() == 'q':
            break
        elif key.lower() == 'a' or key == readchar.key.LEFT:
            # BAD
            log_binary_eval(
                session_id=session_id,
                is_good=False,
                phase_name=phase_name,
                cascade_id=group.get('cascade_id'),
                output_text=str(winner_sounding.get('content', ''))[:1000] if winner_sounding else None,
                mutation_applied=winner_sounding.get('mutation_applied') if winner_sounding else None
            )
            rated_count += 1
            bad_count += 1
            streak = 0
            print(" BAD")
        elif key.lower() == 'd' or key == readchar.key.RIGHT:
            # GOOD
            log_binary_eval(
                session_id=session_id,
                is_good=True,
                phase_name=phase_name,
                cascade_id=group.get('cascade_id'),
                output_text=str(winner_sounding.get('content', ''))[:1000] if winner_sounding else None,
                mutation_applied=winner_sounding.get('mutation_applied') if winner_sounding else None
            )
            rated_count += 1
            good_count += 1
            streak += 1
            print(" GOOD")
        elif key.lower() == 's' or key == readchar.key.DOWN:
            # SKIP
            skip_count += 1
            print(" SKIP")
        elif key.lower() == 'w' or key == readchar.key.UP:
            # FLAG
            log_flag_eval(
                session_id=session_id,
                flag_reason="Flagged during interactive rating",
                phase_name=phase_name,
                cascade_id=group.get('cascade_id'),
                output_text=str(winner_sounding.get('content', ''))[:1000] if winner_sounding else None
            )
            rated_count += 1
            flag_count += 1
            streak = 0
            print(" FLAGGED")

        import time
        time.sleep(0.3)  # Brief pause to show result

    # Final flush
    flush_evaluations()

    # Summary
    print("\033[2J\033[H", end="")  # Clear
    print()
    print("="*60)
    print("HOT OR NOT - Session Complete!")
    print("="*60)
    print()
    print(f"Rated: {rated_count}")
    print(f"  Good: {good_count}")
    print(f"  Bad:  {bad_count}")
    print(f"  Flagged: {flag_count}")
    print(f"  Skipped: {skip_count}")
    print()
    print("View stats with: windlass hotornot stats")
    print()


def cmd_check(args):
    """Check optional dependencies and provide installation guidance."""
    import subprocess
    import requests

    feature = args.feature

    print()
    print("=" * 70)
    print("Windlass Optional Dependencies Check")
    print("=" * 70)
    print()

    checks = []

    # Check Rabbitize
    if feature in ['rabbitize', 'all']:
        print("ðŸŒ Rabbitize (Visual Browser Automation)")
        print("-" * 70)

        # Check npm/node
        try:
            result = subprocess.run(['npm', '--version'], capture_output=True, text=True, timeout=2)
            if result.returncode == 0:
                npm_version = result.stdout.strip()
                print(f"  âœ“ npm: v{npm_version}")
                npm_installed = True
            else:
                print("  âœ— npm: Not found")
                npm_installed = False
        except Exception:
            print("  âœ— npm: Not installed")
            npm_installed = False

        # Check Rabbitize
        try:
            result = subprocess.run(['npx', 'rabbitize', '--version'], capture_output=True, text=True, timeout=5)
            if result.returncode == 0:
                version = result.stdout.strip()
                print(f"  âœ“ Rabbitize: {version}")
                rabbitize_installed = True
            else:
                print("  âœ— Rabbitize: Not installed")
                rabbitize_installed = False
        except Exception:
            print("  âœ— Rabbitize: Not installed")
            rabbitize_installed = False

        # Check server
        try:
            response = requests.get("http://localhost:3037/", timeout=2)
            print("  âœ“ Rabbitize Server: Running")
            server_running = True
        except:
            print("  âœ— Rabbitize Server: Not running")
            server_running = False

        print()

        if not npm_installed:
            print("  ðŸ“¦ Install Node.js/npm:")
            print("     - Ubuntu/Debian: sudo apt install nodejs npm")
            print("     - macOS: brew install node")
            print("     - Windows: https://nodejs.org/")
            print()

        if npm_installed and not rabbitize_installed:
            print("  ðŸ“¦ Install Rabbitize:")
            print("     npm install -g rabbitize")
            print("     sudo npx playwright install-deps")
            print()

        if rabbitize_installed and not server_running:
            print("  ðŸš€ Start Rabbitize Server:")
            print("     npx rabbitize")
            print("     # Or enable auto-start:")
            print("     export RABBITIZE_AUTO_START=true")
            print()

        if rabbitize_installed and server_running:
            print("  âœ… Rabbitize is fully operational!")
            print()
            print("  Try it:")
            print("     windlass examples/rabbitize_simple_demo.json --input '{\"url\": \"https://example.com\"}'")
            print()

        checks.append(('Rabbitize', rabbitize_installed and server_running))

    # Check Docker
    if feature in ['docker', 'all']:
        print("ðŸ³ Docker (Sandboxed Code Execution)")
        print("-" * 70)

        try:
            result = subprocess.run(['docker', '--version'], capture_output=True, text=True, timeout=2)
            if result.returncode == 0:
                docker_version = result.stdout.strip()
                print(f"  âœ“ Docker: {docker_version}")
                docker_installed = True
            else:
                print("  âœ— Docker: Not installed")
                docker_installed = False
        except Exception:
            print("  âœ— Docker: Not installed")
            docker_installed = False

        # Check if container exists
        try:
            result = subprocess.run(
                ['docker', 'ps', '-a', '--filter', 'name=ubuntu-container', '--format', '{{.Names}}'],
                capture_output=True, text=True, timeout=2
            )
            if 'ubuntu-container' in result.stdout:
                print("  âœ“ ubuntu-container: Exists")
                container_exists = True

                # Check if running
                result = subprocess.run(
                    ['docker', 'ps', '--filter', 'name=ubuntu-container', '--format', '{{.Names}}'],
                    capture_output=True, text=True, timeout=2
                )
                if 'ubuntu-container' in result.stdout:
                    print("  âœ“ ubuntu-container: Running")
                    container_running = True
                else:
                    print("  âš   ubuntu-container: Stopped")
                    container_running = False
            else:
                print("  âœ— ubuntu-container: Not created")
                container_exists = False
                container_running = False
        except Exception:
            container_exists = False
            container_running = False

        print()

        if not docker_installed:
            print("  ðŸ“¦ Install Docker:")
            print("     - Ubuntu: https://docs.docker.com/engine/install/ubuntu/")
            print("     - macOS: brew install --cask docker")
            print("     - Windows: https://docs.docker.com/desktop/install/windows-install/")
            print()

        if docker_installed and not container_exists:
            print("  ðŸš€ Create Ubuntu Container:")
            print("     docker run -d --name ubuntu-container ubuntu:latest sleep infinity")
            print("     docker exec ubuntu-container bash -c \"apt update && apt install -y python3 python3-pip curl wget\"")
            print()

        if docker_installed and container_exists and not container_running:
            print("  ðŸš€ Start Container:")
            print("     docker start ubuntu-container")
            print()

        if docker_installed and container_running:
            print("  âœ… Docker environment is ready!")
            print()
            print("  Try it:")
            print("     windlass examples/simple_flow.json --input '{\"data\": \"test\"}'")
            print()

        checks.append(('Docker', docker_installed and container_running))

    # Summary
    print("=" * 70)
    print("Summary")
    print("=" * 70)
    print()

    for name, status in checks:
        icon = "âœ…" if status else "âŒ"
        status_text = "Ready" if status else "Not Ready"
        print(f"  {icon} {name}: {status_text}")

    print()
    print("For complete setup guides:")
    print("  - Rabbitize: See RABBITIZE_INTEGRATION.md")
    print("  - Docker: See CLAUDE.md section 2.9")
    print()


# ============================================================================
# Harbor Commands (HuggingFace Spaces)
# ============================================================================

def cmd_harbor_list(args):
    """List user's HuggingFace Spaces."""
    try:
        from windlass.harbor import list_user_spaces
        from windlass.config import get_config

        config = get_config()
        if not config.hf_token:
            print("Error: HF_TOKEN environment variable not set")
            print("Get your token at: https://huggingface.co/settings/tokens")
            sys.exit(1)

        spaces = list_user_spaces(
            author=args.author,
            include_sleeping=getattr(args, 'all', False)
        )

        if not spaces:
            print("No Gradio spaces found.")
            if not getattr(args, 'all', False):
                print("(Use --all to include sleeping/paused spaces)")
            return

        # Print header
        print(f"{'SPACE':<40} {'STATUS':<12} {'HARDWARE':<15}")
        print("-" * 70)

        for space in spaces:
            status_icon = {
                "RUNNING": "ðŸŸ¢",
                "SLEEPING": "ðŸ˜´",
                "BUILDING": "ðŸ”¨",
                "PAUSED": "â¸ï¸",
            }.get(space.status, "â“")

            hardware = space.hardware or "â€”"
            print(f"{space.id:<40} {status_icon} {space.status:<10} {hardware:<15}")

        print()
        print(f"Total: {len(spaces)} space(s)")

    except ImportError as e:
        print(f"Error: {e}")
        print("Install required packages: pip install huggingface_hub")
        sys.exit(1)
    except Exception as e:
        print(f"Error: {e}")
        sys.exit(1)


def cmd_harbor_introspect(args):
    """Introspect a Space's API."""
    try:
        from windlass.harbor import get_space_endpoints
        from windlass.config import get_config

        config = get_config()
        if not config.hf_token:
            print("Error: HF_TOKEN environment variable not set")
            sys.exit(1)

        print(f"Introspecting: {args.space}")
        print("-" * 50)

        endpoints = get_space_endpoints(args.space)

        if not endpoints:
            print("No endpoints found (Space may not be a Gradio app)")
            return

        for endpoint in endpoints:
            print(f"\nEndpoint: {endpoint.name}")
            print("  Parameters:")
            if endpoint.parameters:
                for param_name, param_info in endpoint.parameters.items():
                    ptype = param_info.get("type", "Any")
                    component = param_info.get("component", "")
                    desc = param_info.get("description", "")
                    print(f"    - {param_name}: {ptype}")
                    if component:
                        print(f"        Component: {component}")
            else:
                print("    (none)")

            print("  Returns:")
            if endpoint.returns:
                for ret_name, ret_info in endpoint.returns.items():
                    rtype = ret_info.get("type", "Any")
                    print(f"    - {ret_name}: {rtype}")
            else:
                print("    (none)")

    except ImportError as e:
        print(f"Error: {e}")
        print("Install required packages: pip install gradio_client huggingface_hub")
        sys.exit(1)
    except Exception as e:
        print(f"Error: {e}")
        sys.exit(1)


def cmd_harbor_export(args):
    """Export a Space as a .tool.json definition."""
    try:
        from windlass.harbor import export_tool_definition

        tool_def = export_tool_definition(
            space_id=args.space,
            api_name=args.endpoint,
            tool_id=args.tool_id
        )

        json_output = json.dumps(tool_def, indent=2)

        if args.output:
            with open(args.output, 'w') as f:
                f.write(json_output)
            print(f"Exported to: {args.output}")
        else:
            print(json_output)

    except ImportError as e:
        print(f"Error: {e}")
        sys.exit(1)
    except Exception as e:
        print(f"Error: {e}")
        sys.exit(1)


def cmd_harbor_manifest(args):
    """Show auto-discovered Spaces as tools."""
    try:
        from windlass.harbor import get_harbor_manifest, format_harbor_manifest
        from windlass.config import get_config

        config = get_config()
        if not config.hf_token:
            print("Error: HF_TOKEN environment variable not set")
            sys.exit(1)

        print("Discovering HuggingFace Spaces...")
        print()

        manifest = get_harbor_manifest()
        formatted = format_harbor_manifest(manifest)
        print(formatted)

    except ImportError as e:
        print(f"Error: {e}")
        sys.exit(1)
    except Exception as e:
        print(f"Error: {e}")
        sys.exit(1)


def cmd_harbor_wake(args):
    """Wake up a sleeping HF Space."""
    try:
        from windlass.harbor import wake_space

        print(f"Waking space: {args.space}...")

        success, error = wake_space(args.space)
        if success:
            print("Wake request sent successfully.")
            print("Space may take a few minutes to start up.")
        else:
            print(f"Failed to wake space: {error}")
            print()
            print("Common issues:")
            print("  - Space ID must be in format 'author/space-name'")
            print("  - Space must exist and you must have permission to restart it")
            print("  - Check your HF_TOKEN has write permissions")
            sys.exit(1)

    except ImportError as e:
        print(f"Error: {e}")
        sys.exit(1)
    except Exception as e:
        print(f"Error: {e}")
        sys.exit(1)


def cmd_harbor_pause(args):
    """Pause a running HF Space."""
    try:
        from windlass.harbor import pause_space

        print(f"Pausing space: {args.space}...")

        success, error = pause_space(args.space)
        if success:
            print("Pause request sent successfully.")
            print("Space will stop and billing will cease.")
        else:
            print(f"Failed to pause space: {error}")
            print()
            print("Common issues:")
            print("  - Space ID must be in format 'author/space-name'")
            print("  - Space must be running to pause it")
            print("  - Check your HF_TOKEN has write permissions")
            sys.exit(1)

    except ImportError as e:
        print(f"Error: {e}")
        sys.exit(1)
    except Exception as e:
        print(f"Error: {e}")
        sys.exit(1)


def cmd_harbor_status(args):
    """Show summary of all HF Spaces with cost estimates."""
    try:
        from windlass.harbor import get_spaces_summary, HARDWARE_PRICING
        from windlass.config import get_config

        config = get_config()
        if not config.hf_token:
            print("Error: HF_TOKEN environment variable not set")
            print("Get your token at: https://huggingface.co/settings/tokens")
            sys.exit(1)

        print("Fetching HuggingFace Spaces status...")
        print()

        result = get_spaces_summary()
        spaces = result["spaces"]
        summary = result["summary"]

        if not spaces:
            print("No spaces found.")
            return

        # Summary header
        print("=" * 70)
        print("HARBOR STATUS - HuggingFace Spaces Overview")
        print("=" * 70)
        print()
        print(f"  Total Spaces:     {summary['total']}")
        print(f"  Running:          {summary['running']} (billable)")
        print(f"  Sleeping:         {summary['sleeping']}")
        print(f"  Harbor-Callable:  {summary['callable']} (Gradio + Running)")
        print()
        if summary['estimated_hourly_cost'] > 0:
            print(f"  Est. Hourly Cost: ${summary['estimated_hourly_cost']:.2f}/hr")
            print(f"  Est. Monthly:     ${summary['estimated_hourly_cost'] * 24 * 30:.2f}/mo (if always on)")
        else:
            print("  Est. Hourly Cost: $0.00 (all free tier or sleeping)")
        print()

        # By SDK
        print("By SDK:")
        for sdk, count in sorted(summary['by_sdk'].items()):
            print(f"  {sdk}: {count}")
        print()

        # Detailed list
        print("-" * 70)
        print(f"{'SPACE':<35} {'STATUS':<12} {'SDK':<10} {'COST/HR':<10}")
        print("-" * 70)

        # Sort: running first, then by name
        sorted_spaces = sorted(spaces, key=lambda s: (s.status != "RUNNING", s.id))

        for space in sorted_spaces:
            cost_str = f"${space.hourly_cost:.2f}" if space.hourly_cost > 0 else "Free"
            if space.status != "RUNNING":
                cost_str = "-"

            callable_marker = " *" if space.is_callable else ""
            private_marker = " ðŸ”’" if space.private else ""

            print(f"{space.id:<35} {space.status_emoji} {space.status:<10} {space.sdk or '-':<10} {cost_str:<10}{callable_marker}{private_marker}")

        print()
        print("* = Harbor-callable (can be used as a tool)")
        print("ðŸ”’ = Private space")
        print()
        print("Commands:")
        print("  windlass harbor wake <space>   - Wake a sleeping space")
        print("  windlass harbor pause <space>  - Pause a running space (stops billing)")
        print("  windlass harbor introspect <space> - View API endpoints")

    except ImportError as e:
        print(f"Error: {e}")
        print("Install required packages: pip install huggingface_hub")
        sys.exit(1)
    except Exception as e:
        print(f"Error: {e}")
        sys.exit(1)


# ============================================================================
# Triggers Commands (Scheduling & Sensors)
# ============================================================================

def cmd_triggers_list(args):
    """List triggers defined in a cascade."""
    from windlass.triggers import list_triggers

    try:
        triggers = list_triggers(args.cascade)

        if not triggers:
            print()
            print("No triggers defined in this cascade.")
            print()
            print("Add triggers to your cascade JSON:")
            print()
            print('  "triggers": [')
            print('    {"name": "daily", "type": "cron", "schedule": "0 6 * * *"},')
            print('    {"name": "on_data", "type": "sensor", "check": "python:sensors.check_fresh"}')
            print('  ]')
            print()
            return

        print()
        print("="*60)
        print(f"Triggers in {args.cascade}")
        print("="*60)
        print()

        for trigger in triggers:
            enabled = "âœ“" if trigger.get("enabled", True) else "âœ—"
            print(f"  {enabled} {trigger['name']} ({trigger['type']})")

            if trigger['type'] == 'cron':
                print(f"      Schedule: {trigger.get('schedule')}")
                if trigger.get('timezone') != 'UTC':
                    print(f"      Timezone: {trigger.get('timezone')}")
            elif trigger['type'] == 'sensor':
                print(f"      Check: {trigger.get('check')}")
                print(f"      Poll: {trigger.get('poll_interval')}")
            elif trigger['type'] == 'webhook':
                print(f"      Auth: {trigger.get('auth', 'none')}")
            elif trigger['type'] == 'manual':
                if trigger.get('inputs_schema'):
                    print(f"      Inputs: {list(trigger['inputs_schema'].keys())}")

            if trigger.get('description'):
                print(f"      Description: {trigger['description']}")
            print()

        print(f"Total: {len(triggers)} trigger(s)")
        print()
        print("Export triggers:")
        print(f"  windlass triggers export {args.cascade} --format cron")
        print(f"  windlass triggers export {args.cascade} --format kubernetes")
        print()

    except Exception as e:
        print(f"Error: {e}")
        sys.exit(1)


def cmd_triggers_export(args):
    """Export triggers to external scheduler format."""
    from windlass.triggers import export_cron, export_systemd, export_kubernetes, export_airflow
    import os

    cascade_path = os.path.abspath(args.cascade)

    try:
        if args.format == 'cron':
            output = export_cron(args.cascade, cascade_path)

        elif args.format == 'systemd':
            timer_content, service_content = export_systemd(
                args.cascade,
                cascade_path,
                user=args.user
            )
            # For systemd, output both files
            if args.output:
                timer_path = args.output.replace('.service', '.timer')
                if not timer_path.endswith('.timer'):
                    timer_path += '.timer'
                service_path = timer_path.replace('.timer', '.service')

                with open(timer_path, 'w') as f:
                    f.write(timer_content)
                with open(service_path, 'w') as f:
                    f.write(service_content)

                print(f"Exported to:")
                print(f"  {timer_path}")
                print(f"  {service_path}")
                print()
                print("Install with:")
                print(f"  sudo cp {timer_path} {service_path} /etc/systemd/system/")
                print("  sudo systemctl daemon-reload")
                print(f"  sudo systemctl enable --now {os.path.basename(timer_path)}")
                return
            else:
                output = f"# === TIMER FILE ===\n{timer_content}\n\n# === SERVICE FILE ===\n{service_content}"

        elif args.format == 'kubernetes':
            output = export_kubernetes(
                args.cascade,
                cascade_path,
                namespace=args.namespace,
                image=args.image
            )

        elif args.format == 'airflow':
            output = export_airflow(args.cascade, cascade_path)

        else:
            print(f"Unknown format: {args.format}")
            sys.exit(1)

        # Write output
        if args.output:
            with open(args.output, 'w') as f:
                f.write(output)
            print(f"Exported to: {args.output}")
        else:
            print(output)

    except Exception as e:
        print(f"Error: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)


def cmd_triggers_check(args):
    """Check if a sensor trigger condition is met."""
    from windlass.triggers import check_sensor, get_trigger
    from windlass.cascade import SensorTrigger

    try:
        # Verify trigger exists and is a sensor
        trigger = get_trigger(args.cascade, args.trigger_name)

        if not trigger:
            print(f"Trigger '{args.trigger_name}' not found in {args.cascade}")
            sys.exit(1)

        if not isinstance(trigger, SensorTrigger):
            print(f"Trigger '{args.trigger_name}' is not a sensor trigger (type: {trigger.type})")
            sys.exit(1)

        print(f"Checking sensor: {args.trigger_name}")
        print(f"  Check: {trigger.check}")
        print(f"  Args: {trigger.args}")
        print()

        # Run the check
        is_ready, result = check_sensor(args.cascade, args.trigger_name)

        if is_ready:
            print("âœ“ Condition MET - ready to trigger")
            print()
            print(f"Result: {json.dumps(result, indent=2)}")
            sys.exit(0)
        else:
            print("âœ— Condition NOT MET - not ready")
            print()
            print(f"Result: {json.dumps(result, indent=2)}")
            sys.exit(1)

    except Exception as e:
        print(f"Error checking sensor: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)


# =============================================================================
# Signals Commands
# =============================================================================

def cmd_signals_list(args):
    """List signals currently waiting."""
    from windlass.signals import get_signal_manager, SignalStatus

    try:
        manager = get_signal_manager(use_db=True, start_server=False)

        # Determine which status to filter
        status = None if getattr(args, 'all', False) else SignalStatus.WAITING

        signals = manager.list_signals(
            status=status,
            cascade_id=getattr(args, 'cascade', None),
            signal_name=getattr(args, 'name', None)
        )

        if not signals:
            status_desc = "waiting " if status == SignalStatus.WAITING else ""
            print(f"No {status_desc}signals found.")
            print()
            print("To create a signal, use await_signal() in a cascade:")
            print('  result = await_signal("my_signal", timeout="1h")')
            return

        print(f"{'Signal ID':<20} {'Name':<20} {'Status':<10} {'Cascade':<25} {'Created'}")
        print("-" * 100)

        for signal in signals:
            created = signal.created_at.strftime("%Y-%m-%d %H:%M") if signal.created_at else "?"
            print(f"{signal.signal_id:<20} {signal.signal_name:<20} {signal.status.value:<10} {signal.cascade_id[:25]:<25} {created}")

        print()
        print(f"Total: {len(signals)} signal(s)")
        print()
        print("To fire a signal:")
        print("  windlass signals fire <signal_name> --payload '{\"key\": \"value\"}'")

    except Exception as e:
        print(f"Error listing signals: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)


def cmd_signals_fire(args):
    """Fire a signal to wake up waiting cascades."""
    from windlass.signals import fire_signal

    try:
        # Parse payload JSON
        payload = json.loads(args.payload)

        count = fire_signal(
            signal_name=args.signal_name,
            payload=payload,
            source=args.source,
            session_id=getattr(args, 'session', None)
        )

        if count > 0:
            print(f"âœ“ Fired signal '{args.signal_name}' - woke up {count} waiting cascade(s)")
            if payload:
                print(f"  Payload: {json.dumps(payload)}")
        else:
            print(f"No cascades were waiting for signal '{args.signal_name}'")
            print()
            print("To see waiting signals:")
            print("  windlass signals list")

    except json.JSONDecodeError as e:
        print(f"Invalid JSON payload: {e}")
        sys.exit(1)
    except Exception as e:
        print(f"Error firing signal: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)


def cmd_signals_status(args):
    """Check status of a specific signal."""
    from windlass.signals import get_signal_manager

    try:
        manager = get_signal_manager(use_db=True, start_server=False)
        signal = manager.get_signal(args.signal_id)

        if not signal:
            print(f"Signal '{args.signal_id}' not found")
            sys.exit(1)

        print(f"Signal: {signal.signal_id}")
        print(f"  Name: {signal.signal_name}")
        print(f"  Status: {signal.status.value}")
        print(f"  Cascade: {signal.cascade_id}")
        print(f"  Session: {signal.session_id}")
        print(f"  Phase: {signal.phase_name or 'N/A'}")
        print(f"  Created: {signal.created_at.isoformat() if signal.created_at else 'N/A'}")
        print(f"  Timeout: {signal.timeout_at.isoformat() if signal.timeout_at else 'None'}")

        if signal.fired_at:
            print(f"  Fired At: {signal.fired_at.isoformat()}")
            print(f"  Source: {signal.source or 'unknown'}")

        if signal.payload:
            print(f"  Payload: {json.dumps(signal.payload, indent=4)}")

        if signal.description:
            print(f"  Description: {signal.description}")

        if signal.callback_host and signal.callback_port:
            print(f"  Callback: http://{signal.callback_host}:{signal.callback_port}/")

    except Exception as e:
        print(f"Error getting signal status: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)


def cmd_signals_cancel(args):
    """Cancel a waiting signal."""
    from windlass.signals import get_signal_manager

    try:
        manager = get_signal_manager(use_db=True, start_server=False)
        signal = manager.get_signal(args.signal_id)

        if not signal:
            print(f"Signal '{args.signal_id}' not found")
            sys.exit(1)

        if signal.status.value != 'waiting':
            print(f"Cannot cancel signal '{args.signal_id}' - status is '{signal.status.value}'")
            sys.exit(1)

        manager.cancel_signal(args.signal_id, getattr(args, 'reason', None))
        print(f"âœ“ Cancelled signal '{args.signal_id}'")

        if args.reason:
            print(f"  Reason: {args.reason}")

    except Exception as e:
        print(f"Error cancelling signal: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)


# =============================================================================
# Sessions Commands - Durable Execution Coordination
# =============================================================================

def cmd_sessions_list(args):
    """List cascade sessions."""
    from windlass.session_state import get_session_state_manager, SessionStatus

    try:
        manager = get_session_state_manager(use_db=True)

        # Determine status filter
        status_filter = None
        if args.status != 'all':
            status_filter = SessionStatus(args.status)

        sessions = manager.list_sessions(
            status=status_filter,
            cascade_id=getattr(args, 'cascade', None),
            limit=args.limit
        )

        if not sessions:
            status_desc = f"{args.status} " if args.status != 'all' else ""
            print(f"No {status_desc}sessions found.")
            return

        # Header
        print(f"{'SESSION ID':<35} {'CASCADE':<25} {'STATUS':<12} {'PHASE':<20} {'UPDATED':<16}")
        print("-" * 110)

        for session in sessions:
            updated = session.updated_at.strftime("%Y-%m-%d %H:%M") if session.updated_at else "?"
            phase = (session.current_phase or "-")[:20]
            cascade = (session.cascade_id or "?")[:25]
            session_id = session.session_id[:35]

            # Color code status
            status = session.status.value
            if status == 'running':
                status = f"\033[32m{status}\033[0m"  # Green
            elif status == 'blocked':
                status = f"\033[33m{status}\033[0m"  # Yellow
            elif status == 'error':
                status = f"\033[31m{status}\033[0m"  # Red
            elif status == 'orphaned':
                status = f"\033[35m{status}\033[0m"  # Magenta

            print(f"{session_id:<35} {cascade:<25} {status:<21} {phase:<20} {updated}")

        print()
        print(f"Total: {len(sessions)} session(s)")

        # Show commands for common actions
        running_count = sum(1 for s in sessions if s.status == SessionStatus.RUNNING)
        blocked_count = sum(1 for s in sessions if s.status == SessionStatus.BLOCKED)

        if running_count > 0:
            print(f"\n{running_count} running - to cancel: windlass sessions cancel <session_id>")
        if blocked_count > 0:
            print(f"{blocked_count} blocked - see details: windlass sessions show <session_id>")

    except Exception as e:
        print(f"Error listing sessions: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)


def cmd_sessions_show(args):
    """Show details for a specific session."""
    from windlass.session_state import get_session_state_manager

    try:
        manager = get_session_state_manager(use_db=True)
        session = manager.get_session(args.session_id)

        if not session:
            print(f"Session '{args.session_id}' not found")
            sys.exit(1)

        print(f"Session: {session.session_id}")
        print(f"  Cascade: {session.cascade_id}")
        print(f"  Status: {session.status.value}")
        print(f"  Current Phase: {session.current_phase or 'N/A'}")
        print(f"  Depth: {session.depth}")

        if session.parent_session_id:
            print(f"  Parent Session: {session.parent_session_id}")

        print()
        print("Timing:")
        print(f"  Started: {session.started_at.isoformat() if session.started_at else 'N/A'}")
        print(f"  Updated: {session.updated_at.isoformat() if session.updated_at else 'N/A'}")
        if session.completed_at:
            print(f"  Completed: {session.completed_at.isoformat()}")

        print()
        print("Heartbeat:")
        print(f"  Last: {session.heartbeat_at.isoformat() if session.heartbeat_at else 'N/A'}")
        print(f"  Lease: {session.heartbeat_lease_seconds}s")

        # Blocked state
        if session.status.value == 'blocked':
            print()
            print("Blocked State:")
            print(f"  Type: {session.blocked_type.value if session.blocked_type else 'unknown'}")
            print(f"  On: {session.blocked_on or 'N/A'}")
            print(f"  Description: {session.blocked_description or 'N/A'}")
            if session.blocked_timeout_at:
                print(f"  Timeout At: {session.blocked_timeout_at.isoformat()}")

        # Error state
        if session.status.value == 'error':
            print()
            print("Error:")
            print(f"  Phase: {session.error_phase or 'N/A'}")
            print(f"  Message: {session.error_message or 'N/A'}")

        # Cancellation
        if session.cancel_requested:
            print()
            print("Cancellation:")
            print(f"  Requested: Yes")
            print(f"  Reason: {session.cancel_reason or 'N/A'}")
            if session.cancelled_at:
                print(f"  Cancelled At: {session.cancelled_at.isoformat()}")

        # Recovery info
        if session.last_checkpoint_id:
            print()
            print("Recovery:")
            print(f"  Last Checkpoint: {session.last_checkpoint_id}")
            print(f"  Resumable: {session.resumable}")

    except Exception as e:
        print(f"Error getting session: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)


def cmd_sessions_cancel(args):
    """Request cancellation of a running session."""
    from windlass.session_state import get_session_state_manager, SessionStatus

    try:
        manager = get_session_state_manager(use_db=True)
        session = manager.get_session(args.session_id)

        if not session:
            print(f"Session '{args.session_id}' not found")
            sys.exit(1)

        if session.status not in (SessionStatus.RUNNING, SessionStatus.BLOCKED, SessionStatus.STARTING):
            print(f"Cannot cancel session '{args.session_id}' - status is '{session.status.value}'")
            print("Only running, blocked, or starting sessions can be cancelled.")
            sys.exit(1)

        manager.request_cancellation(args.session_id, getattr(args, 'reason', None))
        print(f"âœ“ Cancellation requested for session '{args.session_id}'")
        print()
        print("The session will stop gracefully at the next phase boundary.")
        print("Note: If the session is blocked (waiting for signal/input), it may take")
        print("longer to detect the cancellation request.")

        if args.reason:
            print(f"\nReason: {args.reason}")

    except Exception as e:
        print(f"Error cancelling session: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)


def cmd_sessions_cleanup(args):
    """Mark zombie sessions (expired heartbeat) as orphaned."""
    from windlass.session_state import get_session_state_manager

    try:
        manager = get_session_state_manager(use_db=True)

        # Get zombies first
        zombies = manager.get_zombie_sessions(grace_period_seconds=args.grace)

        if not zombies:
            print("No zombie sessions found.")
            print(f"\nZombie criteria: heartbeat expired + {args.grace}s grace period")
            return

        print(f"Found {len(zombies)} zombie session(s):")
        print()

        for zombie in zombies:
            elapsed = "?"
            if zombie.heartbeat_at:
                from datetime import datetime, timezone
                elapsed_secs = (datetime.now(timezone.utc) - zombie.heartbeat_at).total_seconds()
                elapsed = f"{int(elapsed_secs)}s ago"

            print(f"  {zombie.session_id}")
            print(f"    Cascade: {zombie.cascade_id}")
            print(f"    Status: {zombie.status.value}")
            print(f"    Last Heartbeat: {elapsed}")
            print()

        if args.dry_run:
            print("Dry run - no changes made.")
            print("\nTo mark as orphaned, run without --dry-run:")
            print("  windlass sessions cleanup")
        else:
            count = manager.cleanup_zombies(grace_period_seconds=args.grace)
            print(f"âœ“ Marked {count} session(s) as orphaned")

    except Exception as e:
        print(f"Error cleaning up sessions: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)


if __name__ == "__main__":
    main()
